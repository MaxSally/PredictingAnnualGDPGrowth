{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-6bv7w3__ because the default path (/home/cse479/maxnguyen/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "# We'll start with our library imports...\n",
    "from __future__ import print_function\n",
    "import pandas\n",
    "import seaborn as sn\n",
    "import numpy as np                 # to use numpy arrays\n",
    "import tensorflow as tf            # to specify and run computation graphs\n",
    "import tensorflow_datasets as tfds # to load training data\n",
    "import matplotlib.pyplot as plt    # to visualize data and draw plots\n",
    "from tqdm import tqdm              # to track progress of loops\n",
    "from keras.datasets import cifar100\n",
    "from keras import backend as k \n",
    "import keras\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add, ZeroPadding2D, Add, GlobalAveragePooling2D, Dense, Activation, Flatten, Conv2D, MaxPooling2D, MaxPool2D, BatchNormalization, ReLU, Dropout, GlobalAvgPool2D, Input\n",
    "from functools import partial\n",
    "from keras import backend\n",
    "from tensorflow.python.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images, labels), (temp, temp1) = cifar100.load_data()\n",
    "train_images, validation_images = images[:40000], images[40000:]\n",
    "train_labels, validation_labels = labels[:40000], labels[40000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_width = 32, 32, 3\n",
    "  \n",
    "# if k.image_data_format() == 'channels_first': \n",
    "#    train_images = train_images.reshape(train_images.shape[0], 1, img_rows, img_cols, img_width) \n",
    "#    validation_images = validation_images.reshape(validation_images.shape[0], 1, img_rows, img_cols, img_width) \n",
    "#    inpx = (img_rows, img_cols, img_width)\n",
    "  \n",
    "# else: \n",
    "#    train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, img_width) \n",
    "#    validation_images = validation_images.reshape(validation_images.shape[0], img_rows, img_cols, img_width) \n",
    "#    inpx = (img_rows, img_cols, img_width) \n",
    "  \n",
    "train_images = train_images.astype('float32') \n",
    "validation_images = validation_images.astype('float32') \n",
    "temp = temp.astype('float32')\n",
    "train_images /= 255\n",
    "validation_images /= 255\n",
    "temp /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 100)\n"
     ]
    }
   ],
   "source": [
    "train_labels = keras.utils.to_categorical(train_labels)\n",
    "print(train_labels.shape)\n",
    "validation_labels_save = validation_labels\n",
    "validation_labels = keras.utils.to_categorical(validation_labels)\n",
    "temp1 = keras.utils.to_categorical(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_rows, img_cols, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        # Both self.conv1 and self.down_conv layers downsample the input when stride != 1\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=stride,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            padding=\"same\")\n",
    "\n",
    "        if self.stride != 1:\n",
    "            self.down_conv = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                    kernel_size=(1, 1),\n",
    "                                                    strides=stride,\n",
    "                                                    padding=\"same\")\n",
    "            self.down_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def __call__(self, x, is_training = True):\n",
    "        identity = x\n",
    "        if self.stride != 1:\n",
    "            identity = self.down_conv(identity)\n",
    "            identity = self.down_bn(identity, training=is_training)\n",
    "\n",
    "        x = self.bn1(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        \n",
    "        x = self.bn2(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return x + identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPANSION_FACTOR = 4\n",
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1, padding=\"SAME\", use_bias=False)\n",
    "class Bottleneck(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert filter_num % EXPANSION_FACTOR == 0\n",
    "        \n",
    "        self.conv1 = Conv2D(filter_num // EXPANSION_FACTOR, kernel_size=1, padding='same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.conv2 = Conv2D(filter_num // EXPANSION_FACTOR, kernel_size=3, strides=stride, padding='same')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.conv3 = Conv2D(filter_num, kernel_size=1, padding='same')\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.dropout = Dropout(rate=0.25)\n",
    "        if self.stride != 1:\n",
    "            self.down_conv = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                    kernel_size=(1, 1),\n",
    "                                                    strides=stride,\n",
    "                                                    padding=\"same\")\n",
    "            self.down_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def __call__(self, x, is_training = True):\n",
    "        identity = x\n",
    "        if self.stride != 1:\n",
    "            identity = self.down_conv(identity)\n",
    "            identity = self.down_bn(identity, training=is_training)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.bn3(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x + identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_110 (Conv2D)          (None, 16, 16, 64)        9408      \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_92 (TensorF [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_93 (TensorF [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_94 (TensorF [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 8, 8, 64)          1088      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_38 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_95 (TensorF [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_96 (TensorF [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_97 (TensorF [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 8, 8, 64)          1088      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_39 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_98 (TensorF [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_99 (TensorF [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_100 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 8, 8, 64)          1088      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_40 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_101 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_102 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_103 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 8, 8, 64)          1088      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_41 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_104 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_105 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_106 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 8, 8, 64)          1088      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_42 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_107 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_108 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_109 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 8, 8, 64)          1088      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_43 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_110 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_111 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_112 (Tensor [(None, 8, 8, 16)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 8, 8, 64)          1088      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_44 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_113 (Tensor [(None, 8, 8, 64)]        0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 8, 8, 32)          2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_114 (Tensor [(None, 8, 8, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_115 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 4, 4, 128)         8320      \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 4, 4, 128)         4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_130 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_45 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_116 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 4, 4, 32)          4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_117 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_133 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_118 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 4, 4, 128)         4224      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_46 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_134 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_119 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 4, 4, 32)          4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_135 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_120 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_136 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_121 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 4, 4, 128)         4224      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_47 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_137 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_122 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 4, 4, 32)          4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_138 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_123 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_139 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_124 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 4, 4, 128)         4224      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_48 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_140 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_125 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 4, 4, 32)          4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_141 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_126 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_142 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_127 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_148 (Conv2D)          (None, 4, 4, 128)         4224      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_49 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_143 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_128 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 4, 4, 32)          4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_144 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_129 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_130 (Tensor [(None, 4, 4, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 4, 4, 128)         4224      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_50 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_146 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_131 (Tensor [(None, 4, 4, 128)]       0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_152 (Conv2D)          (None, 4, 4, 64)          8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_147 (Bat (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_132 (Tensor [(None, 4, 4, 64)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_148 (Bat (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_133 (Tensor [(None, 2, 2, 64)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_155 (Conv2D)          (None, 2, 2, 256)         33024     \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 2, 2, 256)         16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_149 (Bat (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_51 (Tensor [(None, 2, 2, 256)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_150 (Bat (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_134 (Tensor [(None, 2, 2, 256)]       0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_156 (Conv2D)          (None, 2, 2, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_151 (Bat (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_135 (Tensor [(None, 2, 2, 64)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_152 (Bat (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_136 (Tensor [(None, 2, 2, 64)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 2, 2, 256)         16640     \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_52 (Tensor [(None, 2, 2, 256)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_153 (Bat (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_137 (Tensor [(None, 2, 2, 256)]       0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 2, 2, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_154 (Bat (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_138 (Tensor [(None, 2, 2, 64)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_160 (Conv2D)          (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_139 (Tensor [(None, 2, 2, 64)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 2, 2, 256)         16640     \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_53 (Tensor [(None, 2, 2, 256)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 1, 1, 64)          802816    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 1,209,540\n",
      "Trainable params: 1,203,076\n",
      "Non-trainable params: 6,464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(DefaultConv2D(64, kernel_size=7, strides=2,\n",
    "input_shape=input_shape))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "prev_filters = 64\n",
    "is_training = True\n",
    "x = DefaultConv2D(64, kernel_size=7, strides=2,\n",
    "input_shape=input_shape)\n",
    "for filters in [64] * 3 + [64] * 4 + [128] * 6 + [256] * 3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(Bottleneck(filters, stride=strides))\n",
    "    prev_filters = filters\n",
    "model.add(x)\n",
    "model.add(keras.layers.GlobalAvgPool2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 4.3350 - accuracy: 0.0475 - val_loss: 4.0461 - val_accuracy: 0.0885\n",
      "Epoch 2/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9481 - accuracy: 0.0981 - val_loss: 3.7877 - val_accuracy: 0.1277\n",
      "Epoch 3/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.7379 - accuracy: 0.1303 - val_loss: 3.6131 - val_accuracy: 0.1605\n",
      "Epoch 4/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6002 - accuracy: 0.1551 - val_loss: 3.5057 - val_accuracy: 0.1718\n",
      "Epoch 5/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4948 - accuracy: 0.1704 - val_loss: 3.3709 - val_accuracy: 0.1979\n",
      "Epoch 6/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4016 - accuracy: 0.1869 - val_loss: 3.2964 - val_accuracy: 0.2130\n",
      "Epoch 7/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3080 - accuracy: 0.2048 - val_loss: 3.2346 - val_accuracy: 0.2200\n",
      "Epoch 8/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.2359 - accuracy: 0.2195 - val_loss: 3.1708 - val_accuracy: 0.2314\n",
      "Epoch 9/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1537 - accuracy: 0.2365 - val_loss: 3.1016 - val_accuracy: 0.2457\n",
      "Epoch 10/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0872 - accuracy: 0.2482 - val_loss: 3.0455 - val_accuracy: 0.2488\n",
      "Epoch 11/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.0332 - accuracy: 0.2557 - val_loss: 2.9702 - val_accuracy: 0.2678\n",
      "Epoch 12/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9772 - accuracy: 0.2688 - val_loss: 2.9447 - val_accuracy: 0.2729\n",
      "Epoch 13/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9273 - accuracy: 0.2742 - val_loss: 2.8906 - val_accuracy: 0.2838\n",
      "Epoch 14/500\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8784 - accuracy: 0.2859 - val_loss: 2.8601 - val_accuracy: 0.2933\n",
      "Epoch 15/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8358 - accuracy: 0.2937 - val_loss: 2.8153 - val_accuracy: 0.2984\n",
      "Epoch 16/500\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7811 - accuracy: 0.3051 - val_loss: 2.7676 - val_accuracy: 0.3075\n",
      "Epoch 17/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.7498 - accuracy: 0.3098 - val_loss: 2.7421 - val_accuracy: 0.3155\n",
      "Epoch 18/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7154 - accuracy: 0.3177 - val_loss: 2.7413 - val_accuracy: 0.3157\n",
      "Epoch 19/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.6784 - accuracy: 0.3254 - val_loss: 2.7098 - val_accuracy: 0.3254\n",
      "Epoch 20/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.6512 - accuracy: 0.3334 - val_loss: 2.6696 - val_accuracy: 0.3324\n",
      "Epoch 21/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.6167 - accuracy: 0.3373 - val_loss: 2.6292 - val_accuracy: 0.3386\n",
      "Epoch 22/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.5840 - accuracy: 0.3457 - val_loss: 2.6251 - val_accuracy: 0.3403\n",
      "Epoch 23/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.5546 - accuracy: 0.3510 - val_loss: 2.6058 - val_accuracy: 0.3437\n",
      "Epoch 24/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.5439 - accuracy: 0.3544 - val_loss: 2.5712 - val_accuracy: 0.3470\n",
      "Epoch 25/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.5099 - accuracy: 0.3609 - val_loss: 2.5735 - val_accuracy: 0.3527\n",
      "Epoch 26/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.4851 - accuracy: 0.3645 - val_loss: 2.5341 - val_accuracy: 0.3560\n",
      "Epoch 27/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.4566 - accuracy: 0.3711 - val_loss: 2.5387 - val_accuracy: 0.3534\n",
      "Epoch 28/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.4429 - accuracy: 0.3744 - val_loss: 2.5260 - val_accuracy: 0.3555\n",
      "Epoch 29/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.4201 - accuracy: 0.3763 - val_loss: 2.5255 - val_accuracy: 0.3586\n",
      "Epoch 30/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.4025 - accuracy: 0.3826 - val_loss: 2.4782 - val_accuracy: 0.3718\n",
      "Epoch 31/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.3829 - accuracy: 0.3876 - val_loss: 2.5158 - val_accuracy: 0.3636\n",
      "Epoch 32/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.3597 - accuracy: 0.3936 - val_loss: 2.4782 - val_accuracy: 0.3690\n",
      "Epoch 33/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.3454 - accuracy: 0.3960 - val_loss: 2.4785 - val_accuracy: 0.3709\n",
      "Epoch 34/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.3243 - accuracy: 0.3974 - val_loss: 2.4615 - val_accuracy: 0.3754\n",
      "Epoch 35/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.3153 - accuracy: 0.4012 - val_loss: 2.4687 - val_accuracy: 0.3763\n",
      "Epoch 36/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.3007 - accuracy: 0.4078 - val_loss: 2.4404 - val_accuracy: 0.3820\n",
      "Epoch 37/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.2823 - accuracy: 0.4062 - val_loss: 2.4385 - val_accuracy: 0.3824\n",
      "Epoch 38/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.2700 - accuracy: 0.4140 - val_loss: 2.4394 - val_accuracy: 0.3843\n",
      "Epoch 39/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.2573 - accuracy: 0.4159 - val_loss: 2.4302 - val_accuracy: 0.3796\n",
      "Epoch 40/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.2400 - accuracy: 0.4173 - val_loss: 2.4028 - val_accuracy: 0.3920\n",
      "Epoch 41/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.2253 - accuracy: 0.4200 - val_loss: 2.3975 - val_accuracy: 0.3935\n",
      "Epoch 42/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.2194 - accuracy: 0.4250 - val_loss: 2.4016 - val_accuracy: 0.3932\n",
      "Epoch 43/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.1977 - accuracy: 0.4283 - val_loss: 2.3861 - val_accuracy: 0.3963\n",
      "Epoch 44/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.1894 - accuracy: 0.4257 - val_loss: 2.3808 - val_accuracy: 0.3991\n",
      "Epoch 45/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.1698 - accuracy: 0.4333 - val_loss: 2.3964 - val_accuracy: 0.3887\n",
      "Epoch 46/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.1678 - accuracy: 0.4328 - val_loss: 2.3832 - val_accuracy: 0.3940\n",
      "Epoch 47/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.1565 - accuracy: 0.4346 - val_loss: 2.3755 - val_accuracy: 0.3999\n",
      "Epoch 48/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.1413 - accuracy: 0.4380 - val_loss: 2.3727 - val_accuracy: 0.4002\n",
      "Epoch 49/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.1236 - accuracy: 0.4429 - val_loss: 2.3697 - val_accuracy: 0.4041\n",
      "Epoch 50/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.1187 - accuracy: 0.4446 - val_loss: 2.3615 - val_accuracy: 0.4030\n",
      "Epoch 51/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.1068 - accuracy: 0.4462 - val_loss: 2.3767 - val_accuracy: 0.4009\n",
      "Epoch 52/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.0891 - accuracy: 0.4505 - val_loss: 2.3679 - val_accuracy: 0.4026\n",
      "Epoch 53/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.0874 - accuracy: 0.4486 - val_loss: 2.3612 - val_accuracy: 0.4029\n",
      "Epoch 54/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.0743 - accuracy: 0.4574 - val_loss: 2.3671 - val_accuracy: 0.4092\n",
      "Epoch 55/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.0664 - accuracy: 0.4564 - val_loss: 2.3369 - val_accuracy: 0.4078\n",
      "Epoch 56/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.0565 - accuracy: 0.4562 - val_loss: 2.3399 - val_accuracy: 0.4117\n",
      "Epoch 57/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.0519 - accuracy: 0.4585 - val_loss: 2.3266 - val_accuracy: 0.4100\n",
      "Epoch 58/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.0360 - accuracy: 0.4618 - val_loss: 2.3168 - val_accuracy: 0.4130\n",
      "Epoch 59/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.0300 - accuracy: 0.4626 - val_loss: 2.3234 - val_accuracy: 0.4135\n",
      "Epoch 60/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.0212 - accuracy: 0.4652 - val_loss: 2.3525 - val_accuracy: 0.4109\n",
      "Epoch 61/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.0087 - accuracy: 0.4691 - val_loss: 2.3175 - val_accuracy: 0.4142\n",
      "Epoch 62/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.0119 - accuracy: 0.4665 - val_loss: 2.3155 - val_accuracy: 0.4151\n",
      "Epoch 63/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9991 - accuracy: 0.4704 - val_loss: 2.2983 - val_accuracy: 0.4170\n",
      "Epoch 64/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9827 - accuracy: 0.4721 - val_loss: 2.3046 - val_accuracy: 0.4171\n",
      "Epoch 65/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9684 - accuracy: 0.4769 - val_loss: 2.3221 - val_accuracy: 0.4135\n",
      "Epoch 66/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9713 - accuracy: 0.4737 - val_loss: 2.2976 - val_accuracy: 0.4225\n",
      "Epoch 67/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9626 - accuracy: 0.4781 - val_loss: 2.3198 - val_accuracy: 0.4127\n",
      "Epoch 68/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9489 - accuracy: 0.4825 - val_loss: 2.3381 - val_accuracy: 0.4118\n",
      "Epoch 69/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.9552 - accuracy: 0.4801 - val_loss: 2.2958 - val_accuracy: 0.4206\n",
      "Epoch 70/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9464 - accuracy: 0.4807 - val_loss: 2.2930 - val_accuracy: 0.4218\n",
      "Epoch 71/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.9313 - accuracy: 0.4850 - val_loss: 2.2931 - val_accuracy: 0.4246\n",
      "Epoch 72/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9310 - accuracy: 0.4852 - val_loss: 2.3295 - val_accuracy: 0.4144\n",
      "Epoch 73/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.9287 - accuracy: 0.4828 - val_loss: 2.2820 - val_accuracy: 0.4269\n",
      "Epoch 74/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9090 - accuracy: 0.4887 - val_loss: 2.2800 - val_accuracy: 0.4238\n",
      "Epoch 75/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.9092 - accuracy: 0.4888 - val_loss: 2.2868 - val_accuracy: 0.4218\n",
      "Epoch 76/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.9090 - accuracy: 0.4888 - val_loss: 2.2854 - val_accuracy: 0.4251\n",
      "Epoch 77/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8887 - accuracy: 0.4931 - val_loss: 2.2966 - val_accuracy: 0.4252\n",
      "Epoch 78/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.8931 - accuracy: 0.4929 - val_loss: 2.3113 - val_accuracy: 0.4223\n",
      "Epoch 79/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8779 - accuracy: 0.4970 - val_loss: 2.2900 - val_accuracy: 0.4248\n",
      "Epoch 80/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.8833 - accuracy: 0.4937 - val_loss: 2.3056 - val_accuracy: 0.4172\n",
      "Epoch 81/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8770 - accuracy: 0.4970 - val_loss: 2.2928 - val_accuracy: 0.4292\n",
      "Epoch 82/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8601 - accuracy: 0.4993 - val_loss: 2.2831 - val_accuracy: 0.4247\n",
      "Epoch 83/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.8579 - accuracy: 0.4996 - val_loss: 2.2741 - val_accuracy: 0.4271\n",
      "Epoch 84/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8555 - accuracy: 0.5037 - val_loss: 2.2756 - val_accuracy: 0.4330\n",
      "Epoch 85/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8483 - accuracy: 0.5037 - val_loss: 2.3063 - val_accuracy: 0.4241\n",
      "Epoch 86/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8448 - accuracy: 0.5039 - val_loss: 2.2645 - val_accuracy: 0.4351\n",
      "Epoch 87/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8411 - accuracy: 0.5058 - val_loss: 2.2820 - val_accuracy: 0.4291\n",
      "Epoch 88/500\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 1.8314 - accuracy: 0.5081 - val_loss: 2.2741 - val_accuracy: 0.4311\n",
      "Epoch 89/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8227 - accuracy: 0.5110 - val_loss: 2.2856 - val_accuracy: 0.4297\n",
      "Epoch 90/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.8230 - accuracy: 0.5115 - val_loss: 2.3014 - val_accuracy: 0.4250\n",
      "Epoch 91/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.8171 - accuracy: 0.5088 - val_loss: 2.2740 - val_accuracy: 0.4344\n",
      "Epoch 92/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.8053 - accuracy: 0.5130 - val_loss: 2.3028 - val_accuracy: 0.4246\n",
      "Epoch 93/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.8056 - accuracy: 0.5118 - val_loss: 2.2855 - val_accuracy: 0.4304\n",
      "Epoch 94/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7975 - accuracy: 0.5141 - val_loss: 2.2678 - val_accuracy: 0.4343\n",
      "Epoch 95/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7950 - accuracy: 0.5146 - val_loss: 2.2698 - val_accuracy: 0.4323\n",
      "Epoch 96/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7840 - accuracy: 0.5205 - val_loss: 2.2723 - val_accuracy: 0.4353\n",
      "Epoch 97/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7880 - accuracy: 0.5192 - val_loss: 2.2804 - val_accuracy: 0.4283\n",
      "Epoch 98/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7848 - accuracy: 0.5200 - val_loss: 2.3015 - val_accuracy: 0.4279\n",
      "Epoch 99/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7669 - accuracy: 0.5213 - val_loss: 2.2834 - val_accuracy: 0.4328\n",
      "Epoch 100/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7607 - accuracy: 0.5249 - val_loss: 2.2890 - val_accuracy: 0.4291\n",
      "Epoch 101/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7605 - accuracy: 0.5231 - val_loss: 2.2825 - val_accuracy: 0.4328\n",
      "Epoch 102/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7585 - accuracy: 0.5214 - val_loss: 2.2904 - val_accuracy: 0.4321\n",
      "Epoch 103/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7563 - accuracy: 0.5232 - val_loss: 2.2762 - val_accuracy: 0.4363\n",
      "Epoch 104/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7472 - accuracy: 0.5272 - val_loss: 2.2763 - val_accuracy: 0.4317\n",
      "Epoch 105/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7414 - accuracy: 0.5304 - val_loss: 2.2738 - val_accuracy: 0.4322\n",
      "Epoch 106/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7493 - accuracy: 0.5259 - val_loss: 2.2685 - val_accuracy: 0.4324\n",
      "Epoch 107/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7390 - accuracy: 0.5240 - val_loss: 2.2839 - val_accuracy: 0.4323\n",
      "Epoch 108/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7274 - accuracy: 0.5277 - val_loss: 2.2937 - val_accuracy: 0.4320\n",
      "Epoch 109/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7348 - accuracy: 0.5270 - val_loss: 2.2747 - val_accuracy: 0.4355\n",
      "Epoch 110/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7221 - accuracy: 0.5301 - val_loss: 2.2955 - val_accuracy: 0.4284\n",
      "Epoch 111/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7166 - accuracy: 0.5341 - val_loss: 2.2976 - val_accuracy: 0.4280\n",
      "Epoch 112/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7211 - accuracy: 0.5282 - val_loss: 2.2696 - val_accuracy: 0.4349\n",
      "Epoch 113/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7076 - accuracy: 0.5341 - val_loss: 2.2731 - val_accuracy: 0.4340\n",
      "Epoch 114/500\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.7121 - accuracy: 0.5311 - val_loss: 2.2904 - val_accuracy: 0.4355\n",
      "Epoch 115/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.7010 - accuracy: 0.5371 - val_loss: 2.2842 - val_accuracy: 0.4379\n",
      "Epoch 116/500\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.6978 - accuracy: 0.5385 - val_loss: 2.2839 - val_accuracy: 0.4333\n"
     ]
    }
   ],
   "source": [
    "# using Sequential groups all the layers to run at once\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience = 30)\n",
    "history = model.fit(train_images, train_labels, batch_size = 32, epochs=500, validation_data=(validation_images, validation_labels), callbacks = [es], shuffle=True, use_multiprocessing=(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 2.2839 - accuracy: 0.4333\n"
     ]
    }
   ],
   "source": [
    "validation_evaluation = model.evaluate(validation_images, validation_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 2.2426 - accuracy: 0.4401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2425618171691895, 0.4401000142097473]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(temp, temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5zUlEQVR4nO3dd3iUVfbA8e9JIT2EhBaSQELvhI6IvVFEcLGggr3rWnZ1bfvbtay7usXdtWJZy65YwYIKonQQQXpvoSaQkB7S29zfH3fAEBKYIMNkMufzPHmYeducC+Q9894qxhiUUkqpuvh5OgCllFKNlyYJpZRS9dIkoZRSql6aJJRSStVLk4RSSql6aZJQSilVL00SyqeIyLsi8icXj90jIhe6OyalGjNNEkoppeqlSUIpLyQiAZ6OQfkGTRKq0XFW8zwsIutFpFhE/iMibURklogUisgcEWlR4/jLRGSTiOSLyAIR6VFjX38RWe0872MguNZnXSoia53nLhWRvi7GOEZE1ojIIRFJFZEna+0f4bxevnP/jc7tISLyDxHZKyIFIrLEue1cEUmr4+/hQufrJ0Vkmoi8LyKHgBtFZIiI/Oj8jHQReVlEmtU4v5eIfC8iuSJyUEQeF5G2IlIiIjE1jhsoIlkiEuhK2ZVv0SShGqsJwEVAV2AsMAt4HGiJ/X97H4CIdAU+BB4AWgEzga9EpJnzhvkF8D8gGvjUeV2c5w4A3gbuAGKA14EZIhLkQnzFwPVAFDAGuEtExjuv294Z70vOmJKBtc7z/g4MBIY7Y/od4HDx72QcMM35mVOBauBB7N/JGcAFwN3OGCKAOcC3QDugMzDXGJMBLACuqnHdScBHxphKF+NQPkSThGqsXjLGHDTG7AcWA8uNMWuMMeXA50B/53FXA98YY7533uT+DoRgb8LDgEDgX8aYSmPMNGBFjc+4DXjdGLPcGFNtjHkPKHeed1zGmAXGmA3GGIcxZj02UZ3j3H0dMMcY86Hzc3OMMWtFxA+4GbjfGLPf+ZlLnWVyxY/GmC+cn1lqjFlljFlmjKkyxuzBJrnDMVwKZBhj/mGMKTPGFBpjljv3vYdNDIiIP3ANNpEqdQxNEqqxOljjdWkd78Odr9sBew/vMMY4gFQgzrlvvzl6Fsu9NV53AH7rrK7JF5F8IMF53nGJyFARme+spikA7sR+o8d5jZ11nNYSW91V1z5XpNaKoauIfC0iGc4qqD+7EAPAl0BPEemIfVorMMb8dJIxqSZOk4TydgewN3sARESwN8j9QDoQ59x2WPsar1OBZ40xUTV+Qo0xH7rwuR8AM4AEY0xzYApw+HNSgU51nJMNlNWzrxgIrVEOf2xVVU21p2x+DdgKdDHGRGKr404UA8aYMuAT7BPPZPQpQh2HJgnl7T4BxojIBc6G199iq4yWAj8CVcB9IhIgIr8ChtQ4903gTudTgYhImLNBOsKFz40Aco0xZSIyBLi2xr6pwIUicpXzc2NEJNn5lPM28IKItBMRfxE5w9kGsh0Idn5+IPB74ERtIxHAIaBIRLoDd9XY9zXQVkQeEJEgEYkQkaE19v8XuBG4DHjfhfIqH6VJQnk1Y8w2bP36S9hv6mOBscaYCmNMBfAr7M0wD9t+8VmNc1di2yVedu5PcR7riruBp0WkEPgDNlkdvu4+YDQ2YeViG637OXc/BGzAto3kAs8DfsaYAuc138I+BRUDR/V2qsND2ORUiE14H9eIoRBblTQWyAB2AOfV2P8DtsF8tbM9Q6k6iS46pJRvEpF5wAfGmLc8HYtqvDRJKOWDRGQw8D22TaXQ0/Goxkurm5TyMSLyHnYMxQOaINSJ6JOEUkqpeumThFJKqXp53SRhLVu2NImJiZ4OQymlvMqqVauyjTG1x96ckNclicTERFauXOnpMJRSyquIyN4TH3UsrW5SSilVL00SSiml6qVJQimlVL28rk2iLpWVlaSlpVFWVubpUNwuODiY+Ph4AgN1fRillPs1iSSRlpZGREQEiYmJHD3hZ9NijCEnJ4e0tDSSkpI8HY5Sygc0ieqmsrIyYmJimnSCABARYmJifOKJSSnVODSJJAE0+QRxmK+UUynVODSJ6iallGqqCkor2bi/gPVpBfSJa86ILi1PfNIp1GSeJDwpPz+fV199tcHnjR49mvz8/FMfkFLK61VUOXjo03X0e+o7rntrOc9/u5Ufdmaf9jj0SeIUOJwk7r777qO2V1dX4+/vX+95M2fOdHdoSqlGZmlKNu8u3cPd53UmOSEKgLLKap79ZgvNQwK5fngHwoMCuOv91SzcnsVNZyZyXrfW9I1vTlRos9MeryaJU+DRRx9l586dJCcnExgYSHh4OLGxsaxdu5bNmzczfvx4UlNTKSsr4/777+f2228Hfp5ipKioiFGjRjFixAiWLl1KXFwcX375JSEhIR4umVKqNmMMe3JKaBcVTFBA/V8Ca8ssLOPZb7bw5doDiMDiHdm8NmkAyQlR3PreSlbtywPgjUW7iI0KJjW3hOcn9OHqwe1PcGX3anJJ4qmvNrH5wKFTes2e7SL549he9e5/7rnn2LhxI2vXrmXBggWMGTOGjRs3Humm+vbbbxMdHU1paSmDBw9mwoQJxMTEHHWNHTt28OGHH/Lmm29y1VVXMX36dCZNmnRKy6GUOnnGGBZsy+LFeTtYsy+frm3CeeGqZHrHNT/m2LS8Epr5+9EyPIj0Q2W8uWgXH63Yh8MB913QhSsHxnPH/1Zx63sriY0K5mBBOS9fM4Be7SJ5a8ku5m7J5NXrBjKyd1sPlPRoTS5JNAZDhgw5ahzDiy++yOeffw5AamoqO3bsOCZJJCUlkZycDMDAgQPZs2fP6QpXKZ/mcBj8/I7fa3Dj/gL+8OVGVu/LJy4qhAcu7MIHy/cx/pUfuOvcTlzeP46klmHszSnhuVlb+XZTBgABfoIBBBiXHMe953cmqWUYAB/dMYw7/ruKjfsLePfmwQzvZBuk/zS+D38a78YCN1CTSxLH+8Z/uoSFhR15vWDBAubMmcOPP/5IaGgo5557bp3jHIKCgo689vf3p7S09LTEqpSvSs0t4a+ztzFzQzq920VyTrfWnN2lJX3jo2gW4Icxhu0Hi3h/2V6mLt9LdFgz/vKrPlwxMJ5Afz9uHJ7IH77cxEvzUnhpXgoJ0SFkFJQR6O/H/Rd0oWVEEOn5pfj7CROHtCcu6ujq48jgQKbeOpTSymrCghrvrbjxRuZFIiIiKCysexXIgoICWrRoQWhoKFu3bmXZsmWnOTqlfE9qbgklFdV0bh2Ov/Mpoayymt3ZxWw+cIhV+/KYtjINPz+4cmA82w8W8vK8Hbw4dwdBAX70jW/O3pwSMgvL8RO4/oxEHryoK81Dfp4OJyq0GS9e05+HLu7Gwu2ZLNqRzTldW3HfBV1oHRHsUpx+ftKoEwRokjglYmJiOPPMM+nduzchISG0adPmyL6RI0cyZcoU+vbtS7du3Rg2bJgHI1Wq6Zux7gC//WQtldWG0Gb+dG4dTnZhOemHyji8WnNQgB+XJbfjtxd3Jba5/YafX1LBsl25/LQ7lzWpeQxJiuasLi05q0sr2kXV34mkfUwok89IZPIZiaehdKef161xPWjQIFN70aEtW7bQo0cPD0V0+vlaeZVy1Ts/7OaprzYzJDGaqwcnsGF/ASmZRbSOCCIhOpSOrcLo1S6SxJgwAvx9a5iYiKwyxgxq6Hn6JKGU8gplldWkZBaR1DKMsKAADpVV8u3GDOZuOUhWYTl5JZXszi7m4p5tePGa/gQH+jNhYLynw/Z6miSUUo3C9oOFzNlykNyiCvJKKmkfHcrEIQm0iQxmyY5sHvt8Pam5pYhAQotQMg6VUVHlIC4qhKSWYcRGhXDFwHjuOLujzz0luJMmCaWUx1RWO1i0PYt3l+5h8Q475URIoD9RoYF8tqaMl+btoG98c1bvyyepZRh/ndCXjENlbM04xPndWzMuuR3JCVE68aUbaZJQSp1WldUOVuzJZdaGDL7ZkE5ucQVtIoN4+JJuTBycQEy47Q6+N6eY95ftZc6WTO4+txP3XdCF4EDXRzirU8OtSUJERgL/BvyBt4wxz9Xafy7wJbDbuekzY8zT7oxJKeV+C7dnsXxXDgAGqKp2UF7lIPNQOT+kZFNYXkVwoB8X9mjDZf3acV731gTWqiLqEBPGE2N68sSYnh4ogTrMbUlCRPyBV4CLgDRghYjMMMZsrnXoYmPMpe6KQyl1+mQUlPHUV5uYtTEDfz/h8EDmAD8/mgX4EREcwOg+sZzXvTVndWnZ6McIKPc+SQwBUowxuwBE5CNgHFA7Sfic8PBwioqKPB2GUr9IaUU1c7ce5NuNGRzIL6WovIrU3FIcxvDwJd247ayONAvQBmRv584kEQek1nifBgyt47gzRGQdcAB4yBizqfYBInI7cDtA+/aenRFRKV+yL6eEf87ZTvOQQO44pyOxzUPYn1/Kq/NT+HzNfkoqqmkZHkT3thG0jghmSFI0t53VkQ4xYSe+uPIK7kwSdXU3qD1ybzXQwRhTJCKjgS+ALsecZMwbwBtgB9Od4jh/sUceeYQOHTocWU/iySefRERYtGgReXl5VFZW8qc//Ylx48Z5OFKl6meMYcP+giMjledvy+Tfc3bg7ydUVDn4YPk+zugUw1LnwjeX949jfP84hibFHJn6QjU97kwSaUBCjffx2KeFI4wxh2q8nikir4pIS2PMyS+/NOtRyNhw0qfXqW0fGPVcvbsnTpzIAw88cCRJfPLJJ3z77bc8+OCDREZGkp2dzbBhw7jsssu0q55qlA7kl/L45xtYsC3rqO2X9GrDU5f1psrh4LUFO5m9KYOrBiVw93mdj5mwTjVN7kwSK4AuIpIE7AcmAtfWPEBE2gIHjTFGRIZgl1PNcWNMbtG/f38yMzM5cOAAWVlZtGjRgtjYWB588EEWLVqEn58f+/fv5+DBg7Rt6/n54ZVvqqx28NGKVLILy3EYg8MYjIGySgefrEyl2mF4fHR3uraJoLSimpYRQQxOjD5y/rOX9+HZy/t4sATKE9yWJIwxVSJyLzAb2wX2bWPMJhG507l/CnAFcJeIVAGlwETzSyeTOs43fne64oormDZtGhkZGUycOJGpU6eSlZXFqlWrCAwMJDExsc4pwpU6lYwxVDkM1Q6Dn8iRhuPi8irumrqaRdvtk4II+IkgztdndGrJn8b1pn1MqAejV42RW/ufGWNmAjNrbZtS4/XLwMvujOF0mThxIrfddhvZ2dksXLiQTz75hNatWxMYGMj8+fPZu3evp0NUTZgxhumr9/PsN5vJK6kEoJm/H+d1b8XoPrH8Z8luNh04xPMT+nDVoASt9lQu007Kp0ivXr0oLCwkLi6O2NhYrrvuOsaOHcugQYNITk6me/fung5RebnvNmXw55lbaBURxIQB8VzUsw0V1XaA2otzdzB3ayaDOrTg3G6t8Pfz4+ChMr7ZkM7sTQcJDvTjjckDuaBHmxN/kFI16FThXsjXyuvr8ksqeOqrzXy+Zj/d2kRQ5XCwM6v4qGOCA/14+JLu3Dg88aieRtUOw0+7c4ltHkxiS+2W6st0qnClvFxBSSWvLkwhJqwZ1w7tQHhQAHM2H+TxzzeQW1zBAxd24Z7zOhPgJ6xPK2DZrhwiQwKJDmtGn7jmdS6M4+8nnNEppo5PU8o1miSUagR+2p3LAx+tIeNQGQ4Dr8zfSb+EKBZtz6J72wjevnEwveOaHzm+X0IU/RKiPBew8hlNJkkYY3yiMc7bqgdV/fbnl7J4exaLd2Qza2M6CdGhfHb3mQjw6oIUfkjJ4b7zO3Pv+V10egvlMU0iSQQHB5OTk0NMTEyTThTGGHJycggOdm2RddU4LNiWyaYDhxjbtx3tY0LJKizn+W+3Mm1VGgCtI4K4/oxEHrqkG+HOCe9en9zgqmOl3KJJJIn4+HjS0tLIyso68cFeLjg4mPh4XZLRG+zOLuaZrzczb2smAH+bvY1hHaPZdOAQZZXV3HF2R64YGE/n1uFN+suN8m5NIkkEBgaSlJTk6TCUwhjDsl25vL98L7M3ZhAc6M/jo7szqncsn63ez+dr0hjYoQX/d2lPOrUK93S4Sp1Qk+gCq5SnVDsMX607wKyN6RzIL+NAfik5xRU0Dwk8st5y60itHlSep11glTqNyiqrmbUxnZfmpbArq5iE6BA6tQqnV7tIBnZowdh+7XSpTdUkaJJQqg45ReU88PFayiqr6dgynPYxoYQE+hMU6Me61HxmbcigsLyK7m0jmDJpABf3bIufTpetmiBNEkrV4nAYfvPJOpbvyqVfQnPmbj1IdlHFkf3hQQGM7N2W8clxDO8Uo8lBNWmaJJTCVh8drh56fdEuFm7P4pnxvZk8rMOR/fbHQVRooFYlKZ+hSUL5tMzCMp6csYmZGzLo3jaCIUnRTF2+jzF9Y5k09OelcoMD/TUxKJ+kSUL5pMzCMr7bdJC/zd5GaWU1k4d1ICWziA+W76N9dCjP/aqPjl1QCk0Sykfkl1SwbFcOP6TksHRn9pFZVAd1aMFzE/rSubUds1BUXoUAYUH6q6EUaJJQTVxVtYMX56XwyvwUqh2G0Gb+DE6M5qpBCZzRKYbe7Zof1fAcrslBqaPob4RqstILSrn/w7X8tCeXy/vHMWlYe/rGRxHor5PlKeUqTRKqySkqr+LtJbt5c9Euqo3hn1f34/L+Ot+VOgml+ZC6HDpfCH4n2XHB4QC/Bn4xyd8H6z+xP8YBY/8FiSNO7vN/IU0SymuVVFSRV1JJVEgg/n7Cij25LN6RzbRVaeQWV3BxzzY8NroHSboim2fUvjnuWQJznoTRf4d2ya5do7IMfnwZ+l0DzeOO3Z+fCms/gNY9oNP5dtvq/8KKN6HjuTD6Hw2/QR+2eQbMfBiKMqDDCLj8NYhqf+LzDtu33JY3ezvc8BW06XnsMav/a+OPjIMWiXDogE1KuTvt/vbDoTAd3r0UzrwPznsCAoJOrjwnSeduUl5pb04xE177keyi8qO2B/oLZ3VpxX0XdCFZF+XxjNJ8+PQGKM2Dm2ZBszCoKodXh0HuLmgWAROnQsdzoKoC0tdCeBt7A67do+zbx2DZq/ZmeeM3P9/wK8vgx5dg0T+gqtRu828GAcFQfghadrU352F3wyV/Pvq6qSvgy7uhVTe48CmI6QQH1sD3f4D09RDZzt6ID6yBtn2h9wRY9DcQP+hzBZQX2rJVlkJVGVRX2qcMvwD7+c3CoKIY9iyGsNb2M8UPbpltE8Fhq/8LM34NMV2guhwK0iCkBSQMg/ZDoec4e3x5Ecx+HFa/B4Nuhkv/eVL/LCc7d5MmCeUVDpVVEhEUgIiQV1zBr15bSl5JBb+9uBvF5VWUVFTTPyGKoR2jCW2mD8hud3AzZGyAPlce/U390AF4fwJk7wBHFfS/Dsa9Aov+DvOegXGvwtKX7DflzhfZG2n5IXtuaEtbpXLxnyAqAXbOh/+NtzfqjPUw8jkYdpd9evjgKsjcDD0ug4uegoL9sG0WlOXbG2ncQJtglr8GZz8Mg26B4EhY8R+Y+5RNSqX5UF0BHYbD7oX287uPgeJsKM6CHpfCsHvAPwDy9tgb+oG1EBptb+bNwm0y8Qu0ZXVU2qRXUWTf955g483bC++Msudd8Y797N2L4PM7oPMFMPEDe53qSpto6ut6vW0WtOlt/25OgiYJ1SSt2ZfHK/NTmLMlk86tw7liYDxzNh9k/f4CPrh1KIMSoz0dYuO35WtbZdLvWmgW+suvV11lnwpydkDiWTYJhLSALTNg/l/sjfrq920CWPwPuPBJWPA8dLnQbi/JhWk3Q9ZW6HKRre8vzob9q2DzlyD+cMmf7LWCwuH2hfDpjfbGevkUmPWI/RY/4S3oenH9cToc9sa+9v2jt/cYC5e9bJ9u5v8Jts6E/pPgrN9AcPO6r/VLpa6A/46DyuKft3UYAdd9emr+TVygSUI1KXnFFTwyfT3fbT5IVGggVwyIZ21qPiv35gHwyrUDGNM31sNRNiLG2LrsDZ/ab9JtetnthRnw72RbJRMaA0Pvgn4Tf/42utt5I89Jsd9+xd9+gx56BzRvDzvn2Wt2vsCeB7Dybfj6Qfs56z+1DavGYT8jpgtc8R+I7WeTybtjIHUZBITAvStO/C04dxdMvw32r7Tfqm+dA+36w6F0eHUolBVAZLy9udZVx1+boxq2z7b1+mUFtkqr94T6v627U85OW7VWVmD/vvpeDUERp+3jNUmoJmNdaj53T11NVmE591/YhRuGJx4Zv7Azq4i84oqm/wSRsQHm/xlG/bX+G2tRlq2GydgAG6fb1wCte9pv3wHN4JuHYNU7cPnrtqfMjtn2mLZ9IDDM3sDD29pGX/8AWwWzbZZNGKExUJJtb9bGAdd8ZKtmXhxg6/FvmgUFqTD3GVuV03cixA86+gZckAbvjLZtA8PudK3s1ZW2HSKiHfS98uftW2faevxLX7DtBqpBNEkor5eSWcjU5fuYumwfrSKCePW6AfTzxcbn8kJ4/Rxbb590Dlz/5bHffFf/F2bcBzh/f1v3giG32uqSaTfbXjB9r4KXBsGAyT83dmanwLZvbCIozLBPDANvhMCQn699KB1WvGW/1fe6HJLOslUl2SnQbRRsnAa3zrUJwRXGeOabuzqKJgnldfKKK1i5N481+/JYtiuH1fvyCfQXLu3bjj9c2pMWYc08HaJ7lOTaapy9S23duqMKmsfDGfdCWAx8fies/xiSr4M1/4MxL8DgW34+P309vHWh7QFz9sO2MTO0xpPVpzfB1q8hYSikrYD71kLkL6yaK8yANy+AQ2nQczxc9d4vu5467XRlOuUVCssq+d+yvczdksmafXk4DAT4CT1iI3lkZHeuHBRPy/DT2w/8lKiutDf/0lxbFVKzATRtFWz9yn4zz90FBzfZ6pug5vY4Pz/77XzFW/ab+vqP4ZxH4dxHbXXOd/9n2wRaJNqnjE9v/LmnTFjLY2MZ9VfYNd82HA+/75cnCICItrYdYP6zcNHTv/x6ymvok4Q6bSqrHVz/n5/4cVcOveMiOb97G0Z0bkmfuOaENPOCabiNsU8AxVm2V09kO9i1AJa+aLcfFhBsv213vcQOlEr53naTjGoP0UnQboDd167/z6N4M7fagVfbZ0H7M+CGr20bQf4+eHW47eUTm2yTUNoKuz/xzPpj3TzDxnXtJ0c/ZSifpdVNqlEzxvDYZxv4aEUq/7iyHxMGNvJpMhwO2PyFHaAVP8gOaPr2EUiZ8/MxoTFQkmMHTCVfaxuYg6NsNdKGT23//5BoGP5rGHK7vdGfSMYGiOpgG4IPS5lr+/fn7ba9dM7+HZxx96kusWriNEmoRqXaYXjm682sSc1nQPsojIF3l+7h3vM689Al3Twd3vE5quGr+2BNzf71Yrsrnve47eGzZwnsXw1JZ9uujIHBR1+joth2SY0ffFq7OSpVn0bZJiEiI4F/A/7AW8aY5+o5bjCwDLjaGDPNnTEp96t2GH77yVq+WHuAPnHN+fCnfZRVOhjdpy2/uajr6Q+oNN/2lY+MhVY9ILxV/cdWV9qG443TbKNwl4shbaWdhmHIbRDunGYhtt/xP7NZ2M9zCSnlxdyWJETEH3gFuAhIA1aIyAxjzOY6jnsemO2uWNTpU1Xt4KFP1/HF2gM8fEk37jmvMxVVDlIyi+jSJvyotRvczuGAdR/CnD/adoTDmifY6Re6jbIjfXcvtPP0lBfagU6leXaU8IgH7fEJQ05fzEo1Mu58khgCpBhjdgGIyEfAOGBzreN+DUwHBrsxFnUaLNmRzdNfb2L7waIjCQKgWYAfPdtFnuBsF2VtczYc1zNt8rqPYO1UW91TnGUbfuOHwJXv2cnYsrbaUcYr34HlU+w5Qc0hYbB9ymgWZscF9J5wauJVysu5M0nEAak13qcBQ2seICJxwOXA+RwnSYjI7cDtAO3bN2CqXuVWpRXVrN6Xx9rUfH7cmcOSlGwSokOYMmkgI3u3PXUf5HDA9m/tTX33QkDglu/tjf0wY+xMnfOftTOARrW3Yw/OewL6XPXzJHSdL4Az7rEN0XsW28nWYvud/FoBSjVx7kwSddUr1G4l/xfwiDGm+niLzhtj3gDeANtwfaoCVA1njOHHXTlMX7WfbzemU1xRDUBiTCi/G9mNm89MIjjwF9xwqyqg8ICd6ycw2E5O98O/7LTPkXFw/v/ZuYO+uh/uWAj+gXaOoFkP2+39roHLXrLbjyco3FY3KaWOy51JIg2oOelMPHCg1jGDgI+cCaIlMFpEqowxX7gxLnWSqh2GP87YyPvL9hERFMClfdsxqk9bkhOiiAr9BaOjHdU2Eez43rYNVJUdvb9NH5jwHzv2wD/Azk300TV2yumBN8K0m+x4hTMfsG0JOgWEUqeMO5PECqCLiCQB+4GJwLU1DzDGJB1+LSLvAl9rgmicyquq+c3H6/hmQzp3nN2RBy/q+sueGGpa/zHMfdoOLht8K7TqbhdhqSi2cxJ1vuDoG3/30XYdgYXPw6p37diBy162cxQppU4ptyUJY0yViNyL7bXkD7xtjNkkInc6909x12erUyunqJx7P1jDj7tyeGJ0D247u+Opu3hVuV03IDYZbp3n+lKTo/4KuxbaRWNumuX6ZHNKqQZx6zgJY8xMYGatbXUmB2PMje6MRZ2cFXty+fUHa8gtqeCfV/fj8v6/YKR0dZVdJ6AwHbqPtVVHK9+Bgn1w2b8bthZxZCzctcQOVAtpcfIxKaWOSyf4U/X637K9PDljE/EtQvj87uH0atfAVbt2L7brF5QVQHEO7P3BrloGtlvq2H/ZHkmJZ0HH8xoeYEMWpVdKnRRNEqpOUxbu5LlZWzm/e2v+NTGZyOAT9Baq7ac3Ydbv7MR2IS3sbKfdRtvlKqvK7b7XzgSMNjYr1YhpklBHqahy8PK8Hbw4L4VL+8byz6uTCfR3sRrI4bBVST++Astega6j7FKWzcKOPbbDcPj6Afs0oO0JSjVamiQUVdUOZm3MYOaGdBbvyKaovIorB8bz3IS++LsyjUbGBpj58NHdV4fcASP/Uv8gtRYdYPLnp64QSim30CThw6qqHXy59gAvz09hd3YxbSKDGNsvlgu6t+H87q3xK8mGvD1Hj2yuqboKlv7b9k4KaWG7r0Yn2W6rHc44rWVRSrmHJgkfVV5VzV3vr2be1kx6xkYyZdJALu7Z5ugJ+KbdZBubr5tmxyqAHfi2baadJmPHHCjKsIPcxrxgl95USjUpmiR8UHlVNXc7E8STY3tyw/BEjpkWZfdiO7dRYBhMuxlunw+hLWH6rbbHUlBz6Hw+9LnSNkhrw7NSTZImCR9TUFLJbz9dy9ytmTwzvjeTh3Wo+8CFz9vJ767/Et4eCR9ea9dlzt0Jo/4Gg2624xyUUk2a/pb7iLLKat5buodX5qdQWF7F0+N61Z8g9iyxTxGX/AVa97A9lKZeaZfmnPy5XY1NKeUTNEn4gOyicq57cznbDhZybrdWPDKyOz1ij7O+w4Ln7FPEoJvs+84Xwk3f2qm3m8ednqCVUo2CJokmLruonGvfXMa+3BLevnEQ53dvU//BqT/B4hecTxF/hsCQn/e1H1r/eUqpJkuTRBN2IL+Um95Z4UwQgxkeUwpfPWBXb4sfZKfZju1n13/e/AWkrbBdWc99HIbc7uHolVKNgSaJJiizsIzXFuxk6vJ9+Am8Pbk/w3f+G6a+Znsh9bjMJoTpt/x8Ups+9ulhwA12QR6llEKTRJPzzfp0Hp62jvIqBxMGxHHfiHbEz70bdnwH/SfBuY/ZtgWHA3YvgJydts0hOumE11ZK+R5NEk2Ew2F44fvtvDw/hQHto/jHVckk+R2ET34FBzfawW6Dazw5+PlBp/Ptj1JK1UOTRBNgjOHBT9by5doDXD0ogafPCSNoye9g3Ye28fmaj6HrxZ4OUynlhTRJNAGvL9rFl2sP8MezI7mx6j/Ia++D+NvG5xEPQERbT4eolPJSLiUJEZkOvA3MMsY43BuSaoif1m1k+3fv83GrFIasWogYY0dDj/iNXb1NKaV+AVefJF4DbgJeFJFPgXeNMVvdF5Y6IWPI/ur/GLL6JYYEgqmKRvpdA2c/pCu2KaVOGZeShDFmDjBHRJoD1wDfi0gq8CbwvjGm0o0xqloKSsrZ9s5dDMmazgzOYcDVTxDfbXDD1ohWSikXuNwmISIxwCRgMrAGmAqMAG4AznVHcOpYaTmFrHtlEmMcC1jU6lpG3PAvosODPB2WUqqJcrVN4jOgO/A/YKwxJt2562MRWemu4NTRSsor2fD6LYxxLCB9wG84e+wfdIpupZRbufok8bIxZl5dO4wxukDxaWAcDpa+dg+jKmazt9dddLjsj54OSSnlA1ytxO4hIlGH34hICxG52z0hqbos/d+TXJj/MRvjrqLDFX/xdDhKKR/hapK4zRiTf/iNMSYPuM0tEaljLFr4PUN2vczaiHPodcsUrWJSSp02riYJP6mxvqWI+APN3BOSqmn1rgzaznuAQv/m9Lj9HcTP39MhKaV8iKtJYjbwiYhcICLnAx8C37ovLAWQmlvC+v89QldJI/DylwmKiPF0SEopH+Nqw/UjwB3AXYAA3wFvuSson1ZVDrMeoergZkrTc5hsdnKoxzVE9hnj6ciUUj7I1cF0Duyo69fcG46PMwa++Q2seZ+UoL6kV4YT2W0ibcf91dORKaV8lKvjJLoAfwF6AsGHtxtjOropLt+0fAqseZ/FsTcyeffFPDO+N+cN6+DpqJRSPszVNol3sE8RVcB5wH+xA+vUqbJzHmb246wKOZPrd1/IjcMTmawJQinlYa4miRBjzFxAjDF7jTFPAidcrUZERorINhFJEZFH69g/TkTWi8haEVkpIiMaFn4TUXiQyk9vZZeJ45bC23hqXB/+OLanp6NSSimXG67LRMQP2CEi9wL7gdbHO8HZTfYV4CIgDVghIjOMMZtrHDYXmGGMMSLSF/gEO/2H73A4qP7sDqrLCnk65Ek+vuFCurWN8HRUSikFuP4k8QAQCtwHDMRO9HfDCc4ZAqQYY3YZYyqAj4BxNQ8wxhQZY4zzbRhg8DXLXsF/93yerpzMPVddqglCKdWonPBJwvlEcJUx5mGgCLuuhCvigNQa79OAoXVc/3Jso3hroM5+niJyO3A7QPv2TWithK3fYOY8xRzHYA71vI4hSdGejkgppY5ywicJY0w1MLDmiGsX1XX8MU8KxpjPjTHdgfHAM/XE8IYxZpAxZlCrVq0aGEYjVF0Fc56Ej65lX2BHfm/u4LEx2gahlGp8XG2TWAN86VyVrvjwRmPMZ8c5Jw1IqPE+HjhQ38HGmEUi0klEWhpjsl2My/s4quHDqyFlDmkdr+bizaO468JexEWFeDoypZQ6hqtJIhrI4egeTQY4XpJYAXQRkSRsQ/dE4NqaB4hIZ2Cns+F6AHY+qBwXY/JOP/wLUuaQMeIZLlnUlS5xYdx5TidPR6WUUnVydcS1q+0QNc+pcvaEmg34A28bYzaJyJ3O/VOACcD1IlIJlAJX12jIbnrS18P8v1De9TImrOhFeLDhresHExyok/YppRonV0dcv0Pd7Qk3H+88Y8xMYGatbVNqvH4eeN6lSL1dZRl8djsmNIa78ieRU1LBJ3ecQdvmwSc+VymlPMTV6qava7wOBi7nOO0Lqg4L/gJZW/hx2OvMW1DFXyf0pW98lKejUkqp43K1uml6zfci8iEwxy0RNUWZW+HHl6nqey2/XdOKPnFBXDEw3tNRKaXUCbk6mK62LkATGrDgRsbAzIegWTjvht5EekEZvx/TAz8/XV1OKdX4udomUcjRbRIZ2DUm1IlsnA57FnPowr/ywne5jOzVlqEddfEgpZR3cLW6SeeKOBmFB2H2E1S26cet63tSWV3Io6N8a2oqpZR3c6m6SUQuF5HmNd5Hich4t0XVFOz9EV4/G0dpPnfmTWLdgSJeuCqZxJZhno5MKaVc5mqbxB+NMQWH3xhj8oE/uiWipmDlO/DepVT4BzO+4hk2Syem3Tmcsf3aeToypZRqEFe7wNaVTFw917eUF8K3j0GHM3nc7yF25pUw754zaROp4yGUUt7H1SeJlSLygnNupY4i8k9glTsD81rbZkFVKfv6PcD0zYXceGaiJgillNdyNUn8GqgAPsYuDFQK3OOuoLzahmkQGc/fNkUSGujPrSN0GXCllPdytXdTMXDM8qOqlpJc2DmX3L638vXyg9x1TidahDXzdFRKKXXSXO3d9L2IRNV430JEZrstKm+1ZQY4qpiSnWyfIs7SpwillHdztbqppbNHEwDGmDxOsMa1T9o4nfyQDryREsGd53QiWp8ilFJeztUk4RCRI9NwiEgivrge9fEUZmB2L+a9woGM7RfHPed19nRESin1i7najfUJYImILHS+PxvnmtMKyNpO3ldP0ALDnrYj+fuVfXVuJqVUk+Bqw/W3IjIImxjWAl9iezj5tspS+OJuzKbPCSGQdwKu5I83X05QgC4ipJRqGlyd4O9W4H7sOtVrgWHAjxy9nKnvWfM+bPqMrR1v4rrNQ/nzpHOJCtV2CKVU0+Fqm8T9wGBgrzHmPKA/kOW2qLyBoxp+fJnqdoOYvHc0nRMTuaRXW09HpZRSp5SrSaLMGFMGICJBxpitQDf3heUFtsyAvD3MCL+C7OJKfn9pD0S0HUIp1bS42nCd5hwn8QXwvYjk4cvLlxoDS/5FVVRHHtvcnl/1j9OlSJVSTZKrDdeXO18+KSLzgebAt26LqrHbsxjS17K4yxOUZcB9F3TxdERKKeUWDZ7J1Riz8MRHNXGLX8CEteLZtH4M6xipa0QopZqsk13j2ndt/w52zWdP99tIyati4mBd6lsp1XRpkmiIqgqY/TjEdOblovOICA5gZG/t0aSUaro0STTEijchZwfF5z7NV5tyGJ8cR3CgDpxTSjVdmiRcVZwNC56HThcwvbAnFVUOrh6c4OmolFLKrTRJuKKyDKbdBJXFmEue5YOfUunVLpLecc09HZlSSrmVJokTqa60CWL3Ihj3KksPtWJrRiE3nJHo6ciUUsrtNEkcjzHw5T2wbSaM/jv0u5q3Fu+iZXgzLktu5+nolFLK7TRJHM+uBbD+YzjnURhyGymZhczflsX1ZyRqg7VSyidokjie5VMgrBWMeBCA/yzZTVCAH9cN1bERSinf4NYkISIjRWSbiKSIyKN17L9ORNY7f5aKSD93xtMgOTth+7cw6GYIDCanqJzpq/fzqwHxxIQHeTo6pZQ6LdyWJETEH3gFGAX0BK4RkZ61DtsNnGOM6Qs8A7zhrngabPnr4BcIg24B4KMVqVRUObhlRJKHA1NKqdPHnU8SQ4AUY8wuY0wF8BEwruYBxpilxpg859tl2EWNPK+sANZOhd4TIKINxhimr05jSFI0nVuHezo6pZQ6bdyZJOKA1Brv05zb6nMLMMuN8bhuzftQUQTD7gRgXVoBu7KKmTDgeOErpVTT0+BZYBugrhV4TJ0HipyHTRIj6tl/O3Z9bdq3Pw2Nxus+gvjB0K4/AJ+tTiMowI9RfWLd/9lKKdWIuPNJIg2oOW9FPHUsVCQifYG3gHHGmJy6LmSMecMYM8gYM6hVq1ZuCfaIklzI2ACdLwKgosrBV+sOcFHPNkQGB7r3s5VSqpFxZ5JYAXQRkSQRaQZMBGbUPEBE2gOfAZONMdvdGIvr9i4FDCSdBcCCbZnklVQyYUDjaC5RSqnTyW3VTcaYKhG5F5gN+ANvG2M2icidzv1TgD8AMcCrzvWhq4wxg9wVk0v2LIGAYIgbCMBnq/fTMrwZZ3Vp6dGwlFLKE9zZJoExZiYws9a2KTVe3wrc6s4YGmzPYkgYCgFB5BVXMHfrQSYPSyTAX8cdKqV8j975airJhYMbIdFWNX22Zj+V1YYrB2lVk1LKN2mSqGnPEvtn0lkYY/jwp30kJ0TRIzbSs3EppZSHaJKoac8SCAyFdgNYuTePlMwirh2i8zQppXyXJoma9ixxtkc048Pl+wgPCuDSfjo2QinluzRJHFacDZmbIHEEBSWVfLMhnXHJ7Qht5ta2faWUatQ0SRy2c579M+lsPl+TRnmVg2u0qkkp5eM0SQBUlcP8P0PLrph2/Zm6fB994prrGtZKKZ+nSQJg2WuQtxtG/oUlu/LZkVnEDcMTPR2VUkp5nCaJwgxY9DfoOgo6X8g7P+yhZXgzxmqDtVJKaZJgzlNQXQGXPMvu7GLmbc3k2iHtCQrQNayVUsq3k0RJLqz7EIbcDjGdeG/pHgL9hUnDOng6MqWUahR8O0kcWAMY6HIxhWWVTFuVxpg+sbSODPZ0ZEop1Sj4dpJIX2v/jO3HN+vTKSqv4sYzdQ1rpZQ6zLeTxIE1EN0RQqJYvCOb2ObB9IvXbq9KKXWYjyeJdRCbjMNh+GFnNsM7tcS5roVSSil8OUmU5ELBPmiXzOb0Q+SXVDKiS4yno1JKqUbFd5PEgTX2z9hklqRkA3BmJ119TimlatIkEduPH1Ky6domXHs1KaVULb6bJNLXQnRHygIiWLEnlzM761OEUkrV5rtJwtlovXpfHmWVDkZoklBKqWP4ZpIoznE2Wvfnh5Rs/P2EoR210VoppWrzzSSR7myPaJfMkpQckhOiCA/SxYWUUqo230wSB9YCUBTdmw1p+ZzZSZ8ilFKqLr6ZJNLXQXRHNuYYHAb6d2jh6YiUUqpR8s0kkbkF2vRiQ1oBAH11BTqllKqT7yWJqnLI3QWterAuLZ+4qBBiwoM8HZVSSjVKvpcksneAqYZW3diwv4C+OqGfUkrVy/eSRNZWAAoju7A3p4Q+miSUUqpevpckMreA+LO+1A6e6xsX5dl4lFKqEfO9JJG1FWI6sTa9FIA+2mitlFL18r0kkbkFWnVnQ1oBiTGhNA8N9HRESinVaPlWkqgsg7zd0LoHG/YX0Cc+ytMRKaVUo+bWJCEiI0Vkm4ikiMijdezvLiI/iki5iDzkzlgAyN4OxsGhiM7szy/V8RFKKXUCbksSIuIPvAKMAnoC14hIz1qH5QL3AX93VxxHcfZs2uKIA9CeTUopdQLufJIYAqQYY3YZYyqAj4BxNQ8wxmQaY1YAlW6M42eZW8AvgJ/yWyACvfVJQimljsudSSIOSK3xPs25rcFE5HYRWSkiK7Oysk4+oqytEN2JDRklJLUM05lflVLqBNyZJKSObeZkLmSMecMYM8gYM6hVq1YnH1HmFmjdnX25JXRsGXby11FKKR/hziSRBiTUeB8PHHDj5x1fRQnk7cG06k5qbgnxLUI9FopSSnkLdyaJFUAXEUkSkWbARGCGGz/v+LK3A4ai5l0orqgmIVqThFJKnYjbKuWNMVUici8wG/AH3jbGbBKRO537p4hIW2AlEAk4ROQBoKcx5tApDyhrGwBpAR2ALBJahJzyj1BKqabGrS23xpiZwMxa26bUeJ2BrYZyv17joU1PdqY3B7JoH6NPEkopdSK+M+I6IAja9mFfQQUACdomoZRSJ+Q7ScIpNbeU6LBmhGn3V6WUOiEfTBIl2h6hlFIu8r0kkVeiPZuUUspFPpUkqh2GA/mlmiSUUspFPpUkMg6VUVlttNFaKaVc5FNJYl9OCQAJ0domoZRSrvCpJJGaZ5NEe61uUkopl/hUkkjLLcFPoF2UPkkopZQrfCpJpOaVEts8hEB/nyq2UkqdNJ+6W+7LLSFex0gopZTLfCpJpOaWaHuEUko1gM8kibLKajILy3WMhFJKNYDPJIm0vFJAu78qpVRD+EySSM11jpHQgXRKKeUyn0kSEcEBXNyzDR1idG1rpZRylc/Mlz0oMZpBidGeDkMppbyKzzxJKKWUajhNEkoppeqlSUIppVS9NEkopZSqlyYJpZRS9dIkoZRSql6aJJRSStVLk4RSSql6iTHG0zE0iIhkAXtP8vSWQPYpDKcx0DJ5By2Td2jKZepgjGnV0JO9Lkn8EiKy0hgzyNNxnEpaJu+gZfIOWqZjaXWTUkqpemmSUEopVS9fSxJveDoAN9AyeQctk3fQMtXiU20SSimlGsbXniSUUko1gCYJpZRS9fKZJCEiI0Vkm4ikiMijno7nZIhIgojMF5EtIrJJRO53bo8Wke9FZIfzzxaejrUhRMRfRNaIyNfO915dHgARiRKRaSKy1fnvdYY3l0tEHnT+n9soIh+KSLA3lkdE3haRTBHZWGNbveUQkcec94xtInKJZ6I+vnrK9Dfn/731IvK5iETV2NegMvlEkhARf+AVYBTQE7hGRHp6NqqTUgX81hjTAxgG3OMsx6PAXGNMF2Cu8703uR/YUuO9t5cH4N/At8aY7kA/bPm8slwiEgfcBwwyxvQG/IGJeGd53gVG1tpWZzmcv1sTgV7Oc1513ksam3c5tkzfA72NMX2B7cBjcHJl8okkAQwBUowxu4wxFcBHwDgPx9Rgxph0Y8xq5+tC7I0nDluW95yHvQeM90iAJ0FE4oExwFs1NntteQBEJBI4G/gPgDGmwhiTj3eXKwAIEZEAIBQ4gBeWxxizCMittbm+cowDPjLGlBtjdgMp2HtJo1JXmYwx3xljqpxvlwHxztcNLpOvJIk4ILXG+zTnNq8lIolAf2A50MYYkw42kQCtPRhaQ/0L+B3gqLHNm8sD0BHIAt5xVqO9JSJheGm5jDH7gb8D+4B0oMAY8x1eWp461FeOpnLfuBmY5Xzd4DL5SpKQOrZ5bd9fEQkHpgMPGGMOeTqekyUilwKZxphVno7lFAsABgCvGWP6A8V4R1VMnZx19OOAJKAdECYikzwb1Wnh9fcNEXkCW0099fCmOg47bpl8JUmkAQk13sdjH5e9jogEYhPEVGPMZ87NB0Uk1rk/Fsj0VHwNdCZwmYjswVYBni8i7+O95TksDUgzxix3vp+GTRreWq4Lgd3GmCxjTCXwGTAc7y1PbfWVw6vvGyJyA3ApcJ35eUBcg8vkK0liBdBFRJJEpBm24WaGh2NqMBERbD33FmPMCzV2zQBucL6+AfjydMd2Mowxjxlj4o0xidh/k3nGmEl4aXkOM8ZkAKki0s256QJgM95brn3AMBEJdf4fvADbHuat5amtvnLMACaKSJCIJAFdgJ88EF+DichI4BHgMmNMSY1dDS+TMcYnfoDR2Fb+ncATno7nJMswAvtouB5Y6/wZDcRge2XscP4Z7elYT6Js5wJfO183hfIkAyud/1ZfAC28uVzAU8BWYCPwPyDIG8sDfIhtV6nEfqu+5XjlAJ5w3jO2AaM8HX8DypSCbXs4fJ+YcrJl0mk5lFJK1ctXqpuUUkqdBE0SSiml6qVJQimlVL00SSillKqXJgmllFL10iSh1GkkIucenu1WKW+gSUIppVS9NEkoVQcRmSQiP4nIWhF53bnmRZGI/ENEVovIXBFp5Tw2WUSW1Zi7v4Vze2cRmSMi65zndHJePrzGWhNTnaOYlWqUNEkoVYuI9ACuBs40xiQD1cB1QBiw2hgzAFgI/NF5yn+BR4ydu39Dje1TgVeMMf2wcx2lO7f3Bx7Arm3SETuHlVKNUoCnA1CqEboAGAiscH7JD8FO+uYAPnYe8z7wmYg0B6KMMQud298DPhWRCCDOGPM5gDGmDMB5vZ+MMWnO92uBRGCJ20ul1EnQJKHUsQR4zxjz2FEbRf6v1nHHm9PmeFVI5TVeV6O/h6oR0+ompY41F7hCRFrDkTWQO2B/X65wHnMtsMQYUwDkichZzu2TgYXGrvORJiLjndcIEpHQ01kIpU4F/QajVC3GmM0i8nvgOxHxw86ueQ928aBeIrIKKMC2W4CdXnqKMwnsAm5ybp8MvC4iTzuvceVpLIZSp4TOAquUi0SkyBgT7uk4lDqdtLpJKaVUvfRJQimlVL30SUIppVS9NEkopZSqlyYJpZRS9dIkoZRSql6aJJRSStXr/wE9XtDUAv48ZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0WElEQVR4nO3dd3hc1ZnH8e87o957sSRblivuxsY2YMAYAsYUEzDEBAgtARJCgE0BkmyyycPupi8thJIQTCD0DqaDscG994YtWZKt3nuZs3+cMZZlyZaMRjOjeT/PowfNnXtn3mOb+c05595zxRiDUkop1RWHtwtQSinluzQklFJKdUtDQimlVLc0JJRSSnVLQ0IppVS3NCSUUkp1S0NCqR4SkadE5L4e7psrIud+3ddRyts0JJRSSnVLQ0IppVS3NCTUgOIe5vmpiGwSkXoR+YeIpIrIuyJSKyIfiUh8h/0vEZGtIlIlIotF5KQOz00WkXXu414Awjq910UissF97DIRmXCCNX9PRPaISIWIvCkig9zbRUT+T0RKRKTa3aZx7ufmisg2d22FIvKTE/oDU+o4NCTUQHQ58A1gJHAx8C7wcyAJ+2/+RwAiMhJ4DrgTSAYWAW+JSIiIhACvA/8CEoCX3K+L+9iTgSeBW4BE4DHgTREJ7U2hIjIb+F/gSiAdyAOedz99HnCmux1xwLeAcvdz/wBuMcZEA+OAT3rzvkr1lIaEGogeMsYUG2MKgaXASmPMemNMM/AaMNm937eAd4wxHxpjWoE/AeHAacAMIBi43xjTaox5GVjd4T2+BzxmjFlpjGk3xiwEmt3H9cbVwJPGmHXu+u4FThWRbKAViAZGA2KM2W6MOeg+rhUYIyIxxphKY8y6Xr6vUj2iIaEGouIOvzd28TjK/fsg7Dd3AIwxLiAfyHA/V2iOXAEzr8PvQ4Afu4eaqkSkCshyH9cbnWuow/YWMowxnwAPA38FikXkcRGJce96OTAXyBORz0Tk1F6+r1I9oiGhAtkB7Ic9YOcAsB/0hcBBIMO97ZDBHX7PB/7bGBPX4SfCGPPc16whEjt8VQhgjHnQGDMFGIsddvqpe/tqY8w8IAU7LPZiL99XqR7RkFCB7EXgQhE5R0SCgR9jh4yWAcuBNuBHIhIkIpcB0zoc+wRwq4hMd08wR4rIhSIS3csa/g3cICKT3PMZ/4MdHssVkVPcrx8M1ANNQLt7zuRqEYl1D5PVAO1f489BqW5pSKiAZYzZCVwDPASUYSe5LzbGtBhjWoDLgOuBSuz8xasdjl2DnZd42P38Hve+va3hY+A/gVewvZdhwAL30zHYMKrEDkmVY+dNAK4FckWkBrjV3Q6l+pzoTYeUUkp1R3sSSimluqUhoZRSqlsaEkoppbqlIaGUUqpbQd4uoLeSkpJMdna2t8tQSim/snbt2jJjTHJvj/O7kMjOzmbNmjXeLkMppfyKiOQdf6+j6XCTUkqpbmlIKKWU6paGhFJKqW753ZxEV1pbWykoKKCpqcnbpXhcWFgYmZmZBAcHe7sUpVQAGBAhUVBQQHR0NNnZ2Ry5aOfAYoyhvLycgoIChg4d6u1ylFIBYEAMNzU1NZGYmDigAwJAREhMTAyIHpNSyjcMiJAABnxAHBIo7VRK+YYBExLH09jaTlF1I23tLm+XopRSfiNgQqKlzUVJbTOtHgiJqqoqHnnkkV4fN3fuXKqqqvq8HqWU6isBExJBDjtM0+rq+/tndBcS7e3HvlnYokWLiIuL6/N6lFKqrwyIs5t6IshpQ6Ktve9D4p577uHLL79k0qRJBAcHExUVRXp6Ohs2bGDbtm1ceuml5Ofn09TUxB133MHNN98MHF5ipK6ujgsuuICZM2eybNkyMjIyeOONNwgPD+/zWpVSqjcGXEj85q2tbDtQ0+Vz9c1thAQ5CHb2rgM1ZlAMv754bLfP/+53v2PLli1s2LCBxYsXc+GFF7Jly5avTlN98sknSUhIoLGxkVNOOYXLL7+cxMTEI15j9+7dPPfcczzxxBNceeWVvPLKK1xzjd6RUinlXQMuJI5JoD/u1jpt2rQjrmN48MEHee211wDIz89n9+7dR4XE0KFDmTRpEgBTpkwhNzfX84UqpdRxDLiQONY3/h1FNUQEBzE4McKjNURGRn71++LFi/noo49Yvnw5ERERzJo1q8vrHEJDQ7/63el00tjY6NEalVKqJwJm4hogyOGgzdX3ZzdFR0dTW1vb5XPV1dXEx8cTERHBjh07WLFiRZ+/v1JKecqA60kcS7BTaG7t+5BITEzk9NNPZ9y4cYSHh5OamvrVc3PmzOHRRx9lwoQJjBo1ihkzZvT5+yullKeI6Y9B+j40depU0/mmQ9u3b+ekk0467rGFlQ1UNbYydlCsp8rrFz1tr1JKHSIia40xU3t7XGANNzkdtLsMLj8LRqWU8pbACgn3BXXtHrhWQimlBqLACgn39RGtHpi8VkqpgSiwQsLhuauulVJqIAqokAg+tDSHB9ZvUkqpgSigQiLIYZury4UrpVTPBFRIOByCU8TrPYmoqCivvr9SSvVUQIUE2NVgdU5CKaV6JqCuuAY75NTXZzfdfffdDBkyhB/84AcA/Nd//RciwpIlS6isrKS1tZX77ruPefPm9en7KqWUpw28kHj3Hija3O3TGW3tuFwGQnrR9LTxcMHvun16wYIF3HnnnV+FxIsvvsh7773HXXfdRUxMDGVlZcyYMYNLLrlE71GtlPIrAy8kjkOAvh5smjx5MiUlJRw4cIDS0lLi4+NJT0/nrrvuYsmSJTgcDgoLCykuLiYtLa2P310ppTxn4IXEMb7xA1TVNFFc08S4jFgcffitfv78+bz88ssUFRWxYMECnn32WUpLS1m7di3BwcFkZ2d3uUS4Ukr5ssCZuG6qhuKthEgb0PcX1C1YsIDnn3+el19+mfnz51NdXU1KSgrBwcF8+umn5OXl9en7KaVUf/B4SIiIU0TWi8jbXTwnIvKgiOwRkU0icrLnCnFAewshphWgz+8rMXbsWGpra8nIyCA9PZ2rr76aNWvWMHXqVJ599llGjx7dp++nlFL9oT+Gm+4AtgMxXTx3ATDC/TMd+Jv7v33PGQJAEK1AiEdOg928+fCEeVJSEsuXL+9yv7q6uj5/b6WU8gSP9iREJBO4EPh7N7vMA5421gogTkTSPVKMMwQQglyHehJ6rYRSSh2Pp4eb7gd+BnQ3tpMB5Hd4XODedgQRuVlE1ojImtLS0hOrRAScIThczYAuzaGUUj3hsZAQkYuAEmPM2mPt1sW2o77iG2MeN8ZMNcZMTU5O7vKFenSHvaAQpK3FJ5bmOFH+didBpZR/82RP4nTgEhHJBZ4HZovIM532KQCyOjzOBA709o3CwsIoLy8//geoMxTaW9xLc/hfT8IYQ3l5OWFhYd4uRSkVIDw2cW2MuRe4F0BEZgE/McZc02m3N4Efisjz2AnramPMwd6+V2ZmJgUFBRx3KKq5FhorKXe24cJBfUlob9/K68LCwsjMzPR2GUqpANHvF9OJyK0AxphHgUXAXGAP0ADccCKvGRwczNChQ4+/445F8PpV/GnwI7xems7nd88+kbdTSqmA0S8hYYxZDCx2//5oh+0GuK0/agAgwQbJuPAKHq6Mo6GljYjerOGklFIBJnCuuAaIzwZgmLMEgD0ler2CUkodS2CFRHA4RKeT6rLTHruKNSSUUupYAiskAOKHEl2fT4jTwe7iWm9Xo5RSPi3wQiJhKFKZS05yJLs0JJRS6pgCLyTih0JdEWOTg3W4SSmljiPwQsJ9htOUmCoKqxqpb27zckFKKeW7Ai8k4m1IjA4tB2C3nuGklFLdCryQcPckhog9DVbnJZRSqnuBFxLh8RAaS3xzIaFBeoaTUkodS+CFhAgkZOOo3Mew5CidvFZKqWMIvJAASBwOZbsYmRqlPQmllDqGwAyJ9ElQnc/4+DYOVDdR29Tq7YqUUsonBWZIDJoMwOSgXEDPcFJKqe4EZkikTwAgp3UXALuKdMhJKaW6EpghERYLicOJrdxKbHgw6/ZXersipZTySYEZEgCDJiMHNzB9aALL95Z7uxqllPJJAR0S1BRyTqYhv6KR/IoGb1eklFI+J7BDApgZVQigvQmllOpC4IZE2gRAGNSwg6SoEJZ/qSGhlFKdBW5IhEZB0kjkwAZm5CSy7Msy7C23lVJKHRK4IQF2yOnAek4dlkhxTTP7yuq9XZFSSvkUDYm6Is5ItfeUWKZDTkopdQQNCSCraSfpsWE6L6GUUp0EdkikjQdnCJL3BafmJLJibzkul85LKKXUIYEdEiERkHM2bHuT04clUl7fwqbCam9XpZRSPiOwQwJgzDyo3s/58QcJdgqLNh/0dkVKKeUzNCRGXQCOIKL2vs3M4Um8s+mgngqrlFJuGhIRCTD0LNj2BheOT6ewqpGNBTrkpJRSoCFhjZkHlbmcn1RCsFN4Z9MBb1eklFI+wWMhISJhIrJKRDaKyFYR+U0X+8wSkWoR2eD++ZWn6jmm0ReBOIn+8h3OGJHMos1FOuSklFJ4tifRDMw2xkwEJgFzRGRGF/stNcZMcv/81oP1dC8yEbJnwtbXuXBcGoVVjWzIr/JKKUop5Us8FhLGOnRf0GD3j+9+PR9zCVR8yXlptYQ4Hby9Sc9yUkopj85JiIhTRDYAJcCHxpiVXex2qntI6l0RGdvN69wsImtEZE1paalnih02G4DoA19w5shk3tp4gLZ2l2feSyml/IRHQ8IY026MmQRkAtNEZFynXdYBQ9xDUg8Br3fzOo8bY6YaY6YmJyd7ptj4oRA7GPYuZv6UDEpqm1m6u8wz76WUUn6iX85uMsZUAYuBOZ221xwakjLGLAKCRSSpP2o6igjknAm5S5k9MomEyBBeWpvvlVKUUspXePLspmQRiXP/Hg6cC+zotE+aiIj792nuery3yt7QWdBUTUjpZuZNGsRH20qorG/xWjlKKeVtnuxJpAOfisgmYDV2TuJtEblVRG517zMf2CIiG4EHgQXGm+eeDj3T/nffZ1wxJYuWdhdvbCj0WjlKKeVtQZ56YWPMJmByF9sf7fD7w8DDnqqh16JTIfkk2PsZY2bexbiMGF5aW8D1pw/1dmVKKeUVesV1Zzlnwf4V0NbMFVOy2Hqghm0HarxdlVJKeYWGRGdDz4K2RshfxbxJgwhxOnh5bYG3q1JKKa/QkOgs+3QQB+z7jLiIEM4dk8LrGwppadNrJpRSgUdDorOwWMiYCtvfApeLK6ZkUVHfwic7SrxdmVJK9TsNia6c8l0o3QG73+eMEUmkRIfysl4zoZQKQBoSXRl3OcQNhqV/JsghfPPkDD7dWUppbbO3K1NKqX6lIdEVZxCcfgcUrIbcz7liShbtLsPr6/WaCaVUYNGQ6M6kayAyBT7/C8NTopg8OI6X1ubrfSaUUgFFQ6I7wWFw6g/gy0+gcC0LTsliV3Edn+/RRf+UUoFDQ+JYpt4E4Qnwwa+4dNIg0mPDeOjjPd6uSiml+o2GxLGExcDZP4e8zwnd8y63nJnDqtwKVuz13hqESinVnzQkjmfKDXY9pw9+yYKTU0mKCuWhT3Z7uyqllOoXGhLH4wyCOf8DlbmErX2cW8/K4Ys95azNq/B2ZUop5XEaEj0xbDaMnANL/sS3x4WTGBnCXz/90ttVKaWUx2lI9NR590FrAxHL/sQ1M4bwyY4S9pXVe7sqpZTyKA2JnkoaAVNvgDX/5Dsjmgl2Ck8vz/V2VUop5VEaEr1x1j0QHEHi8v/lwvHpvLSmgLrmNm9XpZRSHqMh0RtRyTDzTtj5DrfllFDX3MYreq8JpdQApiHRWzN+ADEZjNj4ByZlxrJwWS4uly7VoZQamDQkeiskAs78KRSu4e7h+9lbVq/3mlBKDVgaEidi8jUQN4TpeY8xOD6cP3+4S3sTSqkBSUPiRDiD4ay7cRzcwB/H57P9YA1vbTrg7aqUUqrPaUicqAnfgoRhTMt9lJNSI/nLh7tobdf7YCulBhYNiRPlDIJZ9yAl2/jz6J3klTfwwmq9xalSamDpUUiIyB0iEiPWP0RknYic5+nifN64yyFjKidt/gNnDw7igY93U93Y6u2qlFKqz/S0J3GjMaYGOA9IBm4AfuexqvyFwwkXP4A0VfHnuJcpr2vmfxdt93ZVSinVZ3oaEuL+71zgn8aYjR22Bba0cXDqD0nY9SK/nVTF86vz+Xy33r1OKTUw9DQk1orIB9iQeF9EogGdpT3krLshbgjfLvk/hieGcc+rm6jX5TqUUgNAT0PiJuAe4BRjTAMQjB1y6paIhInIKhHZKCJbReQ3XewjIvKgiOwRkU0icnKvW+ALQiLgvPtwlO/m8Sn5FFY18sf3d3q7KqWU+tp6GhKnAjuNMVUicg3wS6D6OMc0A7ONMROBScAcEZnRaZ8LgBHun5uBv/W0cJ8z+iJIGknOzie4dvpgFi7PZUN+lberUkqpr6WnIfE3oEFEJgI/A/KAp491gLHq3A+D3T+dL0ueBzzt3ncFECci6T2u3pc4HHD6nVC8hXtGFJASHcq9r27WayeUUn6tpyHRZowx2A/1B4wxDwDRxztIRJwisgEoAT40xqzstEsG0PHiggL3ts6vc7OIrBGRNaWlpT0s2QvGXwExGUSseojfXDKW7QdrePLzfd6uSimlTlhPQ6JWRO4FrgXeEREntmdwTMaYdmPMJCATmCYi4zrt0tUZUkctgmSMedwYM9UYMzU5ObmHJXtBUAicdjvkfcH5Mfs596RU/u+jXeSV6x3slFL+qach8S3sHMONxpgi7Lf9P/b0TYwxVcBiYE6npwqArA6PMwH/XgTp5O9AeALyyk387pR6gp0O7nphA2067KSU8kM9Cgl3MDwLxIrIRUCTMeaYcxIikiwice7fw4FzgR2ddnsT+I77LKcZQLUx5mAv2+BbQiLhmpfB4STppUt5cfQS1u+v4OFP93i7MqWU6rWeLstxJbAKuAK4ElgpIvOPc1g68KmIbAJWY+ck3haRW0XkVvc+i4C9wB7gCeAHJ9AG35MxBW5ZCuOv4KQdD3N/1uc89Mke1uZVersypZTqFbHz0cfZSWQj8A1jTIn7cTLwkfv01n41depUs2bNmv5+2xNjDDx/NebLj7nK8ScKgzJY9KMziA477nSOUkr1KRFZa4yZ2tvjejon4TgUEG7lvTg2cInAhX9GnKE8Eb+QA5X1/OqNrd6uSimleqynH/Tvicj7InK9iFwPvIMdKlLHE5MO5/830cWreWLMJl5bX8hr6wu8XZVSSvVITyeufwo8DkwAJgKPG2Pu9mRhA8rkayDnbM7OvZ87Ujfyy9e26GmxSim/ENTTHY0xrwCveLCWgUsE5j+JPH81d+3/PU7HAm55OpxXfnA6kaE9/itQSql+d8yehIjUikhNFz+1IlLTX0UOCBEJ8J3XYfwV/Ijn+Wb5E9z1wgZcruOfOKCUUt5yzJAwxkQbY2K6+Ik2xsT0V5EDRlAoXPYETLmBW4LeInjHG/zlw13erkoppbqlZyj1NxG44A+YrOn8JewJ3l+8mE93lBz/OKWU8gINCW8ICkGuWEhIRAz/DL+f/3l1BXV6kyKllA/SkPCWmHTkiqfIMMXc0fhX/vCu3htbKeV7NCS8achpyOxfcJFzBW2r/8ma3ApvV6SUUkfQkPC20++iPXsWvw7+Fw8+9wa5ZXr9hFLKd2hIeJvDgXP+EzjCY/l98338+pGnWL9fFwJUSvkGDQlfEJVC8DUvkhQdxj9cv2Tx3+/mi/VboKEC2lq8XZ1SKoD1aBVYX+JXq8D2VmMVza/fQejO1w9vC46AeQ/DuMu9VpZSyv+d6CqwuiaELwmPI3TBU9Rve5+n311CWVUttyVuIeHlG6G2GE4dGLfbUEr5Dw0JXyNC5Ng5XDPsHG7452pOzy/h0+xnSHv/XqgvgXP/y9sVKqUCiM5J+KjosGAW3jiNMVkpnJV3PYXDFsDn/wfL/+rt0pRSAURDwodFhgbxzxtOYURaLOfsvISyrPPh/V/A1te9XZpSKkBoSPi4mLBgnr5xOoMTo5i199uUxE3EvHoz7F/h7dKUUgFAQ8IPJESG8OItpzJtRAbnF91KqSMZ89wCKNvj7dKUUgOchoSfiIsI4e/fmcp3zz+FK+t+TE2TC9czl0NdqbdLU0oNYHp2kx9xOITbzh7O0KRIbny+jn9X3UfQUxfjPGkuxGbC4NMgZbS3y1RKDSAaEn5o7vh0ghxXcvtzNfym4l+kfX4/YtoBgYlXwexf2NBQSqmvSYeb/NR5Y9O46tqbmdVyP+dFvkTxjavhtNthyyvw0BTY+IK3S1RKDQAaEn7s7FEpPH3jNIpq2/jms/l8OfluuH0NZJ4Cr90C6/7l7RKVUn5OQ8LPTc9J5LmbZ9DS7uKyR5axrDwCrn4Jhp0Nb/4QFv/ehsWyh6Fos7fLVUr5GV3gb4DYX97ATQtXs6+snt/OG8e3T06BF78Du98/vFNIFFz/Dgya5LU6lVLecaIL/GlIDCC1Ta3c/tx6Fu8sZWRqFOeMTuayrHpGZKRAeyv861Joa4abPoCEod4uVynVjzQkFADtLsO/V+axaHMRq3IrcBnD7y+bwJWnZEHpTnjyfAiLtfMWlXlgXDBmHoyfDzGDvF2+UspDfC4kRCQLeBpIA1zA48aYBzrtMwt4A9jn3vSqMea3x3pdDYmeq25o5UfPr+ezXaX85pKxXHdaNuSvgpeuB4cT4rOhuQ4OrAMEolJAnBAeB5c+AoMmH36x5jp7bwuHTmMp5Y98MSTSgXRjzDoRiQbWApcaY7Z12GcW8BNjzEU9fV0Nid5pbmvnh/9ez4fbirnjnBH86JwROB1y5E7lX9pTZ6sLwLTDno/BGQK3LLGBUbQZnroIMqfCgn9DUKhX2qKUOnEnGhIe+1pojDlojFnn/r0W2A5keOr9VNdCg5w8cvXJXHZyBg98vJtvPbac/IqGI3dKHAZn/QwueRDm/RWufBpqCuHN2+36UP/6JogD9nwEr3wX2tu80xilVL/rlzkJEckGlgDjjDE1HbbPAl4BCoAD2F7F1i6Ovxm4GWDw4MFT8vLyPF7zQGOM4fUNhfzq9a0Y4I/zJ3DB+PTuD/jiAfjwVxASbXsON75nQ+K9e2D8FTDqAjAG4gbb+Q2R7l9LKeV1Pjfc9NUbiEQBnwH/bYx5tdNzMYDLGFMnInOBB4wxI471ejrc9PXkVzRw+3Pr2ZBfxe2zh3PXuSNxdB5+AnC54PlvQ94yuP4tSJ9oty/+PSz+nyP3zZoBZ/wYQiLhwHpoKIdTfwiRiZ5vkFKqR3wyJEQkGHgbeN8Y85ce7J8LTDXGlHW3j4bE19fc1s5/vr6FF9cUMHN4EreclcPpw5KODgtXO7TUQ1jMkdsr86CtCRDY9xl8fj/UFHTYQSAuC771LKRP8HBrlFI94XMhISICLAQqjDF3drNPGlBsjDEiMg14GRhijlGUhkTfMMbwzMr9/PmDnVQ1tJIRF86tZ+Vw9fQhXfcsjqWtBXYusmc/DZoE1fnw/DXQWAmn3gbRafZCPoy9TsMZAoNnQEKODlMp1U98MSRmAkuBzdhTYAF+DgwGMMY8KiI/BL4PtAGNwH8YY5Yd63U1JPpWU2s7H24r5l/L81iVW8GUIfH8/vLxDE+J/novXFcCr9wE+5Z0v09MJky+Bs78KTh1QWKlPMnnQsJTNCQ8wxjDa+sL+e3b22hobueqaVl8f9Zw0mLDvt4LtzZBcy0019hrM5wh9nHuUtj1gV02JPsMmP+kvU5DKeURGhKqT5TWNvOXD3fy0poCHCJcNS2LH50zgsQoD10bseHf8PZdEBYH4y6DxOEQmQy1RXaeIyEHxl8JIRFHH1tfZs+8Cv2avR6lAoCGhOpT+RUNPLJ4Dy+uKSA82Mn3Zw3jpplDCQt29v2bFW2Gd34MBzdBW+Ph7Y4gcLVBeDyc/B17573E4dBQBisege1vgTMUxlwCExfY54O/Zs9HqQFKQ0J5xJ6SOn737g4+2l7M0KRI/jB/AqdkJ3jmzVwuqD1gewgxGRCRCPkrbCDseMeuM3VIWKwNjpZ62PwKNFeDIxjSxkPqWIhMssdHJNmeSXQqJI8GZ7C9viN3qe3FhMdD9kwYcpr9XakBSkNCedTnu8u459VNFFY1ct2p2Xx/1jBSY/rxW3tDBZTvsUuIHFqUMDTKPtfaBHs/hfyVULAGynbZ/V2tR75GcARkTLHPlWy1QdPW7D6dF7uWVdoEO4RVugOq9sOUG+CcX+uaVcrvaUgoj6tvbuOP7+9k4fJcHCKce1IKN5w+lBk5PnjRnDF2sry+zP5U50PBati/wk6gT70Rxl1ulxspXGsvGizaZIe8XG2Hex07F8Hoi+CyJ7qeF+nOl5/CB/8Js+6Bk3q8NJlSHqMhofpNblk9z63ez0trCqiob2Hu+DR+eeEYBsWFe7u0vmUMrHwU3rsXYrPsfMehobBJV9kJ9ajkLo55DN7/uQ0gDMz/p503+bq17PkYlj8MJ19rA+54+zdWQoSHhgaV39GQUP2uqbWdJ5bs5a+L9yAIF4xP49ScRE4fnjSwAmPne7DqMXsWVUQiHNxoex/itBcFDpsNKSfZIaq8ZXaNq1Fz4cK/2LsDHlgHF/wB0ifZ10gYanspndUchPXP2KvUR55/eHv+KruO1v7ldt5FBK57y753V1zt8NqtsPU1uP7t7vdTAUVDQnlNQWUDf/lwF4t3llJR3wLAGSOSuHbGEGaPTiHIOQDH80t2wOYXYfeHdpjqkPhsmHgVnPkzO4/RVAPPzrfzJYfEZMLMO2HytXZp9pIdsOl5WLsQ2pvtPpOvhVn3wtI/wZonISoNzvopjL4Y/jnHvu73PoH4IUfW5XLZ1Xs3PAOhsTaUbl3aux5F8TZY/XeoK7bDZWnj7fbGSti3FLKm2xMBesIY2PE2ZE7r+TFgVxoWsUODHbc1lNkr+FWvaUgor3O5DLtKavlgazHPrdrPweomBidEcOe5I5g3KePo+1gMFLXFUJUHyaPsZHhnbS22N9FUbYer1j1tz9oKibJnZ2Hs6b6Tvg2n3g4bn4Mv7rcT9OKA6d+Hs39+eKK+dBf8/Vx7Btfwc23vJiTCfiAfWA9bX4Wz7oFRc+Dv37D7XPXcsZdAqTlgzyDb8irsX2ZPLQ4Otxc+Tvue7Z1seBZaG2xNOWfbuxkOO6f7D/+2Fnj7Tntc8kn2trmd1wHrrL4MVv8DVj8BkSl22fqk4VBXantl+5fD2EvtVfqpY4//d3PI/hWw6CdQlW8Xn5xxqw3QtmaoL4Xo9MOB1NZse4UJOb2/BsfVDoXr7N/38HPtMvxg/55XPGLnvJpr7H5n/gRyZnX9GkWb7LBmH15gqiGhfEpbu4uPthfz0Cd72HqghuEpUVx3WjZzx6V57sI8f3HoFNzNL9leReoYyJgKMR2Wbt+/wvYgZnz/yDsEHrL3M1j0U3vRYXN1hyfErsg7+5c2FFY8Cu/dDSddDPFDISgMynfbD6vqAvs4KBTqS+zhSSPtUimTr7WPP7nP1uEMtkvEj58PuV/Apheher/dJ3Wc/bDLPgOyptn2NVXBO/8BexfbntXml+w+V71ge0vrnobag7aHkTbeDt9tewN2vWfPNht2jg08V5vtUa14xAbI+Pmw9XVoqbVtOuvuwz2dzhoq7MkKW16BTS8c/rPe/YE93Tk8ASpzbW8uOAJSxtg/s4Mbob3Fhvj4+Xbu6VBAB4XZY8PiICjk8Hsd2GDnonYusm0HG/xTrrdn1H1yn71HS+IIe3xdkf3zP/c3cNrt9n3b22DLy7Dkj/ZMPrCncMdl2dcSB0z4FpxyUw/+kR1NQ0L5JJfL8N7WIh78eDc7impxOoQzRiTxzckZfGNMKhEhumbT19beCq2N9kPE4bQ9gEOMsR/W29+yvYK2JnsPkLQJ9ptyeyu01tthstEXQ/LIo1+/Mtd+iHb8VutyQfFm+PITO6Gev+rwUNkhjiC4+EGYfDWsfQreusP2QIo22eXkD10seUhksj21edrNtldWtR9evM5+K4/JsHdFHDTJfvivfBRW/M1+Kx9xvj2BoLnW9tYaKuzPoZWJnSG293DmT+xy9oVrYdlDtqeWNMr2hMr2QPEW+y0+c4r989m72PasOl7g2VH0INvLaWu2w4nBkbb+Eefa4Fz5GKxbaNuYNh7m/unw/FBzHbzxAxuMaRPsPtWFNvBTx9kvB821ULzVhqlx2drGXQ5TruvVP49DNCSUTzPGsKOoljc2HOCtjQcorGokIsTJJRMH8YNZwxmc2IvTS9WJc7UfOc7fV1qboGCV/UYdFHp4ReCO3/Lf/4U9O2vYObYHkD7Rfmsv2mS/xQ+ecXRtbc22FzByztFDL42Vtqe07mn7TTw02v6EJ9hv60kj7GsOmmzD4UQ0VtkhLle7fY/WRvu+DRVQuQ/Kdtttk75te2DhcUceX/6l/Rl+ztFtM8b+eWx/ywZkVKrdb+QFHrkuR0NC+Q2Xy7A6t4LX1hfy6vpC2l2GSydl8L0zhzI67Thj1sp/GWO/FccM8nYlAUlDQvml4pomHvtsL/9elUdTq4tp2QlcMTWTcRmx5CRHEhrkgW+9SgUgDQnl1yrrW3hpbT7PrNjP/ooGABwCZ49K4dcXj9XhKKW+Jg0JNSAcOo12V3EdWwureWZFHm0uw21nD+eKqZmkxw6gi/SU6kcaEmpAKqpu4rdvb2XR5iIAMuLCOXNkMj+cPZyMgXRVt1IepiGhBrRtB2pYua+c1bkVfLzdntN/08yhXDxxEFGhQcRFBBMd1sVSF0opQENCBZDCqkb+/P5OXl1feMT2iVlxzBmbxoXj03UOQ6lONCRUwNldXMuekjpqm9soqm7i4+3FbCyoRtwT3tedls0Zw5NwDNTlQJTqBQ0JpbC9jJfW2LOkyuqaGZ0WzZ3njuC8MWkaFiqgaUgo1UFLm4u3Nh7gr5/uYW9ZPSNSopg8OI4hiZGMGRTD6cOSCAkagKvTKtWNEw0JXThHDUghQQ4un5LJvEmDeGvTAZ5blc+nO0sprbXr+cSEBXH+2DSuPXUIEzLjvFusUj5MexIqoNQ3t7FyXzlvbzzIB9uKqWtu45zRKdw6axiZ8eFEhgYRFRKkQ1NqwNHhJqV6qbaplYXLcnli6T6qG1u/2p4cHcqlkwZx+ZRMRqVGI8e6D4NSfkJDQqkTVNvUypJdZdQ0tbp7GhV8uqOENpchLSaMk4fEMWVIAmeOSGJ4SpSGhvJLGhJK9aHyumYWbSli9b4K1u2vpKDS3lMgPTaMkwfHk5UQwZDECL4xJpWkQL+JkvILGhJKeVBhVSNLdpXy2c5SdhbXUlDZQGu7ISTIwWWTM7hmxhBGp0UPzPt5qwHB50JCRLKAp4E0wAU8box5oNM+AjwAzAUagOuNMeuO9boaEsoXtLsMX5bWsXBZLi+vLaC5zUWI00FOciQTMmOZkZPIjJxEBun6UspH+GJIpAPpxph1IhINrAUuNcZs67DPXOB2bEhMBx4wxkw/1utqSChfU1HfwuKdJewqrmNnUQ3r86uoarAT4RMzY5k3KYPpOQlUN7RSVt9CTlIkYwfF6NyG6lc+d52EMeYgcND9e62IbAcygG0ddpsHPG1sUq0QkTgRSXcfq5RfSIgM4bKTM7967HLZW7Uu3V3KmxsP8Nu3tx11zIiUKC6dnMFV0waTEBnSn+Uq1Sv9MichItnAEmCcMaamw/a3gd8ZYz53P/4YuNsYs6bT8TcDNwMMHjx4Sl5ensdrVqqv7C6uZWdxLQmRISREhrA2r5LX1xeyOreSsGAHC04ZzE0zh5KVoIsSKs/xuZ7EISISBbwC3NkxIA493cUhR6WWMeZx4HGww019XqRSHjQiNZoRqdFfPR6dFsPV04ewu7iWx5bs5ZkVeTy9PJdZo1L49rTBZCaEU1HXQmNrO+MzYkmJCfNi9SrQeTQkRCQYGxDPGmNe7WKXAiCrw+NM4IAna1LKV4xIjeZPV0zkP74xkn+v3M8La/L57tNHz7cNTYrkzBFJXDE1i3EZsQC0tbuoaWrToSrlcZ6cuBZgIVBhjLmzm30uBH7I4YnrB40x0471ujpxrQaq1nYXS3aV0tTqIiEyhGCnsH5/FSv3lbN0dxnNbS5Gp0XjdAi7S+poaXORERfOjJxEzjkphW+MSSVYT8FV3fDFs5tmAkuBzdhTYAF+DgwGMMY86g6Sh4E52FNgb+g8H9GZhoQKRNUNrbyxsZC3Nh4gPCSI0WnRJEWFuEOkgor6FtJiwrh6+mCGpUThEAhyOIgJDyY2PJghiRGEBTu93QzlRT4XEp6iIaHUkdpdhsU7S3hqWS5Ld5d1uU9SVCg/Pm8kV07NwqmLFwYkDQmlFAerG6lpbMNlDK3tLmoa2yivb+Zfy/NYk1fJ8JQoRqZG4XKBweAQwSHC1Ox4rp4+RO+xMYBpSCilumWM4b0tRTy2ZC/1zW043BfyGQxNrS72VzSQkxTJz+aMIjosmILKBpwOBxeMSyMyVG87MxBoSCilTogxhk93lnDf29vZW1Z/xHPRYUFcOTWL9Ngw9pbVU1TdxOCECEanRTM1O57hKdHdvKryNT57nYRSyreJCLNHpzJzeDJLdpUSGRpEZnw4JbVNLFyWx8JlubS5DLHhwaTHhrFibzkNLe0AzB6dwm1nD2fKkHgvt0J5ivYklFLHVFnfgoGvrslwuQz5lQ28ueEAT36xj8qGViJCnMSEBRMTHkRMmD2jKj0ujPEZsUzIjGNIYgQRIfqd1Jt0uEkp1e/qm9t4dX0h+8vrqWlso7qx9auf/IoGapvbvto3OjSIlJhQUmPCSIsJY3hqFGcMT2bsoBi9XWw/0JBQSvkUl8uwr7yeLYXVFFY1UlLTTHFNE8U1TRRVN3GgugmwPZTpQxOYkZPI+MxYnCK0G0NCRAhZCRF6ym4f0TkJpZRPcTiEYclRDEuO6vL5ktomvthTxtLdZazcW8G7W4qO2ic0yMHwlChmjUpm7vh0xqTrEuv9TXsSSimfkF/RwK7iWkRAEErrmtlVVMuWA9Wszq2k3WVIiAzB6RCMMaTFhjF1SAKTB8eRFhNGXEQIabFhxIYHe7spPkl7Ekopv5aVENHtcukV9S28v7WITQVVHFo8OresnhdW5/PUstyv9nMITM1O4LwxqcSEB3OwqomK+mZiw4NJig5ldFoMp2THa2+kF7QnoZTyW63tLvaU1FFR30JVQys7imr4cFsxO4pqv9onOiyI+uY2XO6PumlDE/iPb4xkRk6il6r2Dp24Vkopt8KqRtraXaTGhBEW7KTdZSivb+a9LUU8/MkeSmqbSYkOZVRaNMOSowh2CiJCiNNBdFgQ0R1O502MCmFUajRBfr7CroaEUkr1QFNrO6+sK2BdXhU7i2vIK2ugzWUwGFraXF/1ODqKDg1iek4CkwfHMzI1muzECPaV1bNufxUlNU3MGJbIrFHJpET77g2iNCSUUuprMsbQ0NJOTVMrtU1t1Da1UlDZyMp9FSzbU0ZuecMR+wc5hJjwYCrqWwCYmBXHhePTmD06ldLaZjYWVFHT2MqccWmMz4j16lyIhoRSSnlYTVMre0rqyC2rJyshgvEZsYQGOdh2sIZPd5Tw/tZiNhdWH3GM0yG0uww5yZGcOSKZnORIsuIjKK9vobCyEacDLp44iCGJkR6tXUNCKaV8QH5FA0t3lzEoLowJmXE4RXh3y0He2HCATQVV1LvXvTpEBIyB6UMTSI4OJb+ykcr6FqYNtWdpnToskeiwr39ar4aEUkr5OGMMxTXNFFQ2kBgVyqC4MCrqW3h1XSGvrS+krd1FZnwEkaFOln9ZTk2TXdYkPNhJcnQo3zl1CN89I+eE3luvk1BKKR8nIqTFhpEWe3iCOz02nNvOHs5tZw8/Yt/Wdhcr91awubCasrpmyuqaSY4O7e+SNSSUUsoXBTsdzByRxMwRSV6tw79P/FVKKeVRGhJKKaW6pSGhlFKqWxoSSimluqUhoZRSqlsaEkoppbqlIaGUUqpbGhJKKaW65XfLcohIKZB3gocnAWV9WI4v0Db5B22TfxjIbRpijEnu7cF+FxJfh4isOZG1S3yZtsk/aJv8g7bpaDrcpJRSqlsaEkoppboVaCHxuLcL8ABtk3/QNvkHbVMnATUnoZRSqncCrSehlFKqFzQklFJKdStgQkJE5ojIThHZIyL3eLueEyEiWSLyqYhsF5GtInKHe3uCiHwoIrvd/433dq29ISJOEVkvIm+7H/t1ewBEJE5EXhaRHe6/r1P9uV0icpf739wWEXlORML8sT0i8qSIlIjIlg7bum2HiNzr/szYKSLne6fqY+umTX90/9vbJCKviUhch+d61aaACAkRcQJ/BS4AxgBXicgY71Z1QtqAHxtjTgJmALe523EP8LExZgTwsfuxP7kD2N7hsb+3B+AB4D1jzGhgIrZ9ftkuEckAfgRMNcaMA5zAAvyzPU8Bczpt67Id7v+3FgBj3cc84v4s8TVPcXSbPgTGGWMmALuAe+HE2hQQIQFMA/YYY/YaY1qA54F5Xq6p14wxB40x69y/12I/eDKwbVno3m0hcKlXCjwBIpIJXAj8vcNmv20PgIjEAGcC/wAwxrQYY6rw73YFAeEiEgREAAfww/YYY5YAFZ02d9eOecDzxphmY8w+YA/2s8SndNUmY8wHxpg298MVQKb79163KVBCIgPI7/C4wL3Nb4lINjAZWAmkGmMOgg0SIMWLpfXW/cDPAFeHbf7cHoAcoBT4p3sY7e8iEomftssYUwj8CdgPHASqjTEf4Kft6UJ37Rgonxs3Au+6f+91mwIlJKSLbX577q+IRAGvAHcaY2q8Xc+JEpGLgBJjzFpv19LHgoCTgb8ZYyYD9fjHUEyX3GP084ChwCAgUkSu8W5V/cLvPzdE5BfYYepnD23qYrdjtilQQqIAyOrwOBPbXfY7IhKMDYhnjTGvujcXi0i6+/l0oMRb9fXS6cAlIpKLHQKcLSLP4L/tOaQAKDDGrHQ/fhkbGv7arnOBfcaYUmNMK/AqcBr+257OumuHX39uiMh1wEXA1ebwBXG9blOghMRqYISIDBWREOzEzZterqnXRESw49zbjTF/6fDUm8B17t+vA97o79pOhDHmXmNMpjEmG/t38okx5hr8tD2HGGOKgHwRGeXedA6wDf9t135ghohEuP8NnoOdD/PX9nTWXTveBBaISKiIDAVGAKu8UF+vicgc4G7gEmNMQ4enet8mY0xA/ABzsbP8XwK/8HY9J9iGmdiu4SZgg/tnLpCIPStjt/u/Cd6u9QTaNgt42/37QGjPJGCN++/qdSDen9sF/AbYAWwB/gWE+mN7gOew8yqt2G/VNx2rHcAv3J8ZO4ELvF1/L9q0Bzv3cOhz4tETbZMuy6GUUqpbgTLcpJRS6gRoSCillOqWhoRSSqluaUgopZTqloaEUkqpbmlIKNWPRGTWodVulfIHGhJKKaW6pSGhVBdE5BoRWSUiG0TkMfc9L+pE5M8isk5EPhaRZPe+k0RkRYe1++Pd24eLyEcistF9zDD3y0d1uNfEs+6rmJXySRoSSnUiIicB3wJON8ZMAtqBq4FIYJ0x5mTgM+DX7kOeBu42du3+zR22Pwv81RgzEbvW0UH39snAndh7m+Rg17BSyicFebsApXzQOcAUYLX7S344dtE3F/CCe59ngFdFJBaIM8Z85t6+EHhJRKKBDGPMawDGmCYA9+utMsYUuB9vALKBzz3eKqVOgIaEUkcTYKEx5t4jNor8Z6f9jrWmzbGGkJo7/N6O/n+ofJgONyl1tI+B+SKSAl/dA3kI9v+X+e59vg18boypBipF5Az39muBz4y9z0eBiFzqfo1QEYnoz0Yo1Rf0G4xSnRhjtonIL4EPRMSBXV3zNuzNg8aKyFqgGjtvAXZ56UfdIbAXuMG9/VrgMRH5rfs1rujHZijVJ3QVWKV6SETqjDFR3q5Dqf6kw01KKaW6pT0JpZRS3dKehFJKqW5pSCillOqWhoRSSqluaUgopZTqloaEUkqpbv0/WAkKe+xl8z0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(validation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76 57 35 ... 43 44 73]\n"
     ]
    }
   ],
   "source": [
    "y_prediction_bin = np.array([])\n",
    "\n",
    "for example in y_predict:\n",
    "    maxN = example[0]\n",
    "    ind = 0\n",
    "    for i in range(1, 100):\n",
    "        if example[i] > maxN:\n",
    "            ind = i\n",
    "            maxN = example[i]\n",
    "    y_prediction_bin = np.append(y_prediction_bin, ind)\n",
    "\n",
    "y_prediction_bin = y_prediction_bin.astype(int)\n",
    "print(y_prediction_bin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[69  1  0 ...  0  0  0]\n",
      " [ 1 72  1 ...  0  0  0]\n",
      " [ 1  1 26 ...  0  3  0]\n",
      " ...\n",
      " [ 0  0  0 ... 45  0  0]\n",
      " [ 1  1 14 ...  0 19  0]\n",
      " [ 0  0  0 ...  1  1 37]], shape=(100, 100), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = tf.math.confusion_matrix(validation_labels_save, y_prediction_bin)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"HW1_model2_confusion_matrix.txt\", confusion_matrix.numpy(), fmt='%03.d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% Confidence interval for error hypothesis based on the normal distribution estimator:  (0.5569876011921289, 0.5764124217914222)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "validation_data_error = 1 - validation_evaluation[1]\n",
    "\n",
    "lower_bound_interval = validation_data_error - 1.96 * sqrt( (validation_data_error * (1 - validation_data_error)) / len(validation_labels))\n",
    "upper_bound_interval = validation_data_error + 1.96 * sqrt( (validation_data_error * (1 - validation_data_error)) / len(validation_labels))\n",
    "\n",
    "print(\"The 95% Confidence interval for error hypothesis based on the normal distribution estimator: \", (lower_bound_interval, upper_bound_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_WEIGHT_DECAY = 0.2\n",
    "BATCH_NORM_DECAY = 0.99\n",
    "BATCH_NORM_EPSILON = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of\n",
    "            middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x =  Conv2D(filters1, (1, 1), use_bias=False,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(input_tensor)\n",
    "\n",
    "    x =  BatchNormalization(axis=bn_axis,\n",
    "                                  momentum=BATCH_NORM_DECAY,\n",
    "                                  epsilon=BATCH_NORM_EPSILON)(x)\n",
    "    x =  Activation('relu')(x)\n",
    "\n",
    "    x =  Conv2D(filters2, kernel_size,\n",
    "                      padding='same', use_bias=False,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "\n",
    "    x =  BatchNormalization(axis=bn_axis,\n",
    "                                  momentum=BATCH_NORM_DECAY,\n",
    "                                  epsilon=BATCH_NORM_EPSILON)(x)\n",
    "\n",
    "    x =  Activation('relu')(x)\n",
    "\n",
    "    x =  Conv2D(filters3, (1, 1), use_bias=False,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "\n",
    "    x =  BatchNormalization(axis=bn_axis,\n",
    "                                  momentum=BATCH_NORM_DECAY,\n",
    "                                  epsilon=BATCH_NORM_EPSILON)(x)\n",
    "\n",
    "    x =  add([x, input_tensor])\n",
    "    x =  Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, kernel_size, filters, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of\n",
    "            middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3,\n",
    "    the second conv layer at main path is with strides=(2, 2)\n",
    "    And the shortcut should have strides=(2, 2) as well\n",
    "    \"\"\"\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x =  Conv2D(filters1, (1, 1), use_bias=False,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(input_tensor)\n",
    "    x =  BatchNormalization(axis=bn_axis,\n",
    "                                  momentum=BATCH_NORM_DECAY,\n",
    "                                  epsilon=BATCH_NORM_EPSILON)(x)\n",
    "    x =  Activation('relu')(x)\n",
    "\n",
    "\n",
    "    x =  Conv2D(filters2, kernel_size, strides=strides, padding='same',\n",
    "                      use_bias=False, kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "    x =  BatchNormalization(axis=bn_axis,\n",
    "                                  momentum=BATCH_NORM_DECAY,\n",
    "                                  epsilon=BATCH_NORM_EPSILON)(x)\n",
    "    x =  Activation('relu')(x)\n",
    "\n",
    "    x =  Conv2D(filters3, (1, 1), use_bias=False,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "    x =  BatchNormalization(axis=bn_axis,\n",
    "                                  momentum=BATCH_NORM_DECAY,\n",
    "                                  epsilon=BATCH_NORM_EPSILON)(x)\n",
    "\n",
    "    shortcut =  Conv2D(filters3, (1, 1), strides=strides, use_bias=False,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(input_tensor)\n",
    "    shortcut =  BatchNormalization(axis=bn_axis,\n",
    "                                         momentum=BATCH_NORM_DECAY,\n",
    "                                         epsilon=BATCH_NORM_EPSILON)(shortcut)\n",
    "\n",
    "    x =  add([x, shortcut])\n",
    "    x =  Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50(num_classes, input_shape):\n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        x = Lambda(lambda x: backend.permute_dimensions(x, (0, 3, 1, 2)),\n",
    "                          name='transpose')(img_input)\n",
    "        bn_axis = 1\n",
    "    else:  # channels_last\n",
    "        x = img_input\n",
    "        bn_axis = 3\n",
    "\n",
    "    # Conv1 (7x7,64,stride=2)\n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "\n",
    "    x = Conv2D(64, (7, 7),\n",
    "                      strides=(2, 2),\n",
    "                      padding='valid', use_bias=False,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "    x = BatchNormalization(axis=bn_axis,\n",
    "                                  momentum=BATCH_NORM_DECAY,\n",
    "                                  epsilon=BATCH_NORM_EPSILON)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "\n",
    "    # 3x3 max pool,stride=2\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # Conv2_x\n",
    "\n",
    "    # 11, 64\n",
    "    # 33, 64\n",
    "    # 11, 256\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "\n",
    "    # Conv3_x\n",
    "    #\n",
    "    # 11, 128\n",
    "    # 33, 128\n",
    "    # 11, 512\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "\n",
    "    # Conv4_x\n",
    "    # 11, 256\n",
    "    # 33, 256\n",
    "    # 11, 1024\n",
    "    #x = conv_block(x, 3, [256, 256, 1024])\n",
    "    #x = identity_block(x, 3, [256, 256, 1024])\n",
    "    #x = identity_block(x, 3, [256, 256, 1024])\n",
    "    #x = identity_block(x, 3, [256, 256, 1024])\n",
    "    #x = identity_block(x, 3, [256, 256, 1024])\n",
    "    #x = identity_block(x, 3, [256, 256, 1024])\n",
    "\n",
    "    # 11, 512\n",
    "    # 33, 512\n",
    "    # 11, 2048\n",
    "    #x = conv_block(x, 3, [512, 512, 2048])\n",
    "    #x = identity_block(x, 3, [512, 512, 2048])\n",
    "    #x = identity_block(x, 3, [512, 512, 2048])\n",
    "    \n",
    "    # average pool, 100-d fc, softmax\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(\n",
    "        num_classes, activation='softmax',\n",
    "        kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY),\n",
    "        bias_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "\n",
    "    # Create model.\n",
    "    return Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(100, input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Sequential groups all the layers to run at once\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience = 30)\n",
    "history = model.fit(train_images, train_labels, batch_size = 32, epochs=400, validation_data=(validation_images, validation_labels), callbacks = [es], shuffle=True, use_multiprocessing=(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, 'homework1/cifar100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-env)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
